{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Assistants - Code Interpreter\n",
    "\n",
    "This notebook will find answers to a data set:\n",
    "1. If 1 row in the dataset is 1 sighthing, what's our total sightings?\n",
    "2. Which state has the most sightings?\n",
    "3. Which season has the most sightings?\n",
    "4. What are the top 10 years with the most sightings?\n",
    "5. How many sightings did we have for Washington state in the year 2000?\n",
    "\n",
    "Answers:\n",
    "1. 5021\n",
    "2. Washington (601)\n",
    "3. Summer\n",
    "4. 2004, 2005, 2006, 2003, 2000, 2007, 2008, 2012, 2001, 2011\n",
    "5. 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_openai_api_version = \"2024-10-01-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-2:\n",
    "1. Create an Assistant\n",
    "2. Create a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Create an AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = azure_openai_endpoint,\n",
    "  api_key= azure_openai_key,\n",
    "  api_version=azure_openai_api_version\n",
    ")\n",
    "\n",
    "# Create a file\n",
    "file = client.files.create(\n",
    "  file=open(\"../Data/assistant/bigfootsightings.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# STEP 1: Create an assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "  model=azure_openai_deployment,\n",
    "  name=\"bigfootsightings\",\n",
    "  instructions=\"\"\"You are an assistant answering questions about bigfootsightings dataset.\"\"\",\n",
    "  tools=[{\"type\":\"code_interpreter\"}],\n",
    "  tool_resources={\"code_interpreter\":{\"file_ids\":[file.id]}},\n",
    "  temperature=1,\n",
    "  top_p=1, \n",
    ")\n",
    "\n",
    "# STEP 2: Create a thread\n",
    "thread = client.beta.threads.create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3-6: \n",
    "3. Add a message to the thread\n",
    "4. Run the Assistant\n",
    "5. Check the Run Status\n",
    "6. Display the Assistant's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_SUFFIX = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method.\n",
    "Then reflect on the answers of the two methods you did and ask yourself\n",
    "if it answers correctly the original question.\n",
    "If you are not sure, try another method.\n",
    "- If the methods tried do not give the same result,reflect and\n",
    "try again until you have two methods that have the same result.\n",
    "- If you still cannot arrive to a consistent result, say that\n",
    "you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful\n",
    "and thorough response using Markdown.\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,\n",
    "ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.\n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got\n",
    "to the answer on a section that starts with: \"\\n\\nExplanation:\\n\".\n",
    "In the explanation, mention the column names that you used to get\n",
    "to the final answer and provide the python code you used.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_question =\"\"\"If 1 row in the dataset is 1 sighting, what's our total sightings\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Appending Messages to the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =\"\"\"Which state has the most sightings? Provide the number of sightings in that state\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =\"\"\"Which season has the most sightings?\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =\"\"\"\n",
    "What are the top 10 years with the most sightings? \n",
    "Use the date column and get the year there.\n",
    "Create a markdown table and a bar chart with the sightings in the Y-axis and years in the X-axis and save it to a file named top10.png.\n",
    "Put the value on top of each bar.\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve image output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# enter the file_id inside content example: \"assistant-fYrZ85PwbViKU9mrVoE8dqBO\"\n",
    "image_data = client.files.content(content_block.text.annotations[0].file_path.file_id)\n",
    "image= image_data.write_to_file(\"top10.png\")\n",
    "\n",
    "# Display the image in the default image viewer\n",
    "image = Image.open(\"top10.png\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =\"\"\"How many sightings did we have for Washington state in the year 2000?\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =\"\"\"Using the \"observed\" column, are there any sightings observed at Mt. Mitchell?\n",
    "\"\"\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=PROMPT_SUFFIX + user_question\n",
    ")\n",
    "\n",
    "# STEP 4: Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# STEP 5: Check the run status\n",
    "# Looping until the run completes or fails\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "  )\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "elif run.status == 'requires_action':\n",
    "  # the assistant requires calling some functions\n",
    "  # and submit the tool outputs back to the run\n",
    "  pass\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "# STEP 6: Display the Assistant's Response\n",
    "content_block = messages.data[0].content[0]\n",
    "value = content_block.text.value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
