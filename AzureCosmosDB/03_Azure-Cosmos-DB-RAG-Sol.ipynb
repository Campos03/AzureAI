{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a RAG solution using Azure Cosmos DB Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install azure-core\n",
    "%pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure configurations\n",
    "\n",
    "You always need to run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "azure_openai_api_version = \"2024-10-01-preview\"\n",
    "azure_openai_embedding_size = 1536\n",
    "\n",
    "azure_cosmosdb_endpoint = os.getenv(\"AZURE_COSMOSDB_ENDPOINT\")\n",
    "azure_cosmosdb_key = os.getenv(\"AZURE_COSMOSDB_KEY\")\n",
    "azure_cosmosdb_database = \"recipes-database\"\n",
    "azure_cosmosdb_container = \"recipes-container\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure Cosmos DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container with id '<built-in function id>' created\n"
     ]
    }
   ],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "from azure.cosmos import PartitionKey, exceptions\n",
    "\n",
    "# Setup the connection\n",
    "cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "\n",
    "# Create database\n",
    "db = cosmos_client.create_database_if_not_exists(id=azure_cosmosdb_database)\n",
    "\n",
    "# Author the vector embedding policy\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/contentVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":azure_openai_embedding_size\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "full_text_policy = {\n",
    "   \"defaultLanguage\": \"en-US\",\n",
    "   \"fullTextPaths\": [\n",
    "       {\n",
    "           \"path\": \"/name\",\n",
    "           \"language\": \"en-US\"\n",
    "       },\n",
    "       {\n",
    "           \"path\": \"/description\",\n",
    "           \"language\": \"en-US\"\n",
    "       }\n",
    "   ]\n",
    "}\n",
    "\n",
    "# Add vector indexes to indexing policy\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/contentVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"fullTextIndexes\": [\n",
    "        {\n",
    "            \"path\": \"/name\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/description\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/contentVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=azure_cosmosdb_container,\n",
    "                    partition_key=PartitionKey(path='/id', kind='Hash'),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy,\n",
    "                    full_text_policy=full_text_policy)\n",
    "\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))\n",
    "\n",
    "container = db.get_container_client(azure_cosmosdb_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embeddings separately\n",
    "\n",
    "We are computing the embeddings manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Azure OpenAI client\n",
    "openai_client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key)\n",
    "\n",
    "# Read the recipes.json\n",
    "path = os.path.join('../Data/recipes/', 'recipes.json')\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    recipes = json.load(file)\n",
    "\n",
    "# Convert each recipe dictionary into a formatted string \n",
    "# And store these strings in a list\n",
    "combined_strings = []\n",
    "for recipe in recipes:\n",
    "    combined_string = \"\"\n",
    "    for key, value in recipe.items():\n",
    "        if isinstance(value, list):\n",
    "            combined_string += f\"{key}:\\n\"\n",
    "            for item in value:\n",
    "                combined_string += f\"  - {item}\\n\"\n",
    "        else:\n",
    "            combined_string += f\"{key}: {value}\\n\"\n",
    "    combined_strings.append(combined_string)\n",
    "\n",
    "# Generate embeddings for each combined string\n",
    "content_response = openai_client.embeddings.create(\n",
    "    input=combined_strings, \n",
    "    model=azure_openai_embeddings_deployment, \n",
    "    dimensions=azure_openai_embedding_size\n",
    ")\n",
    "\n",
    "content_embeddings = [recipe.embedding for recipe in content_response.data]\n",
    "\n",
    "# add contentVector field in recipes\n",
    "for i, item in enumerate(recipes):\n",
    "    item['contentVector'] = content_embeddings[i]\n",
    "\n",
    "# Output embeddings to new json file\n",
    "output_path = os.path.join('../Data/recipes/', 'recipesVectors.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(recipes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing item  1\n",
      "writing item  2\n",
      "writing item  3\n",
      "writing item  4\n",
      "writing item  5\n",
      "writing item  6\n",
      "writing item  7\n",
      "writing item  8\n",
      "writing item  9\n",
      "writing item  10\n",
      "writing item  11\n",
      "writing item  12\n",
      "writing item  13\n",
      "writing item  14\n",
      "writing item  15\n",
      "writing item  16\n",
      "writing item  17\n",
      "writing item  18\n",
      "writing item  19\n",
      "writing item  20\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../Data/recipes/recipesVectors.json') as f:\n",
    "   data = json.load(f)\n",
    "\n",
    "container_client = db.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "for item in data:\n",
    "    print(\"writing item \", item['id'])\n",
    "    container_client.upsert_item(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "# Simple function to assist with hybrid search\n",
    "def hybrid_search(user_query, num_results):\n",
    "\n",
    "    # Setup the connection\n",
    "    cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "    database = cosmos_client.get_database_client(azure_cosmosdb_database)\n",
    "    container = database.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "    # Azure OpenAI client\n",
    "    openai_client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key)\n",
    "\n",
    "    # get embedding of user query\n",
    "    response = openai_client.embeddings.create(input=user_query, \n",
    "                                               model=azure_openai_embeddings_deployment, \n",
    "                                               dimensions=azure_openai_embedding_size)\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    # format the query\n",
    "    query ='''\n",
    "                SELECT TOP {0} \n",
    "                    c.id, \n",
    "                    c.name,\n",
    "                    c.description,\n",
    "                    c.cuisine,\n",
    "                    c.difficulty,\n",
    "                    c.prepTime,\n",
    "                    c.cookTime,\n",
    "                    c.totalTime,\n",
    "                    c.servings,\n",
    "                    c.ingredients,\n",
    "                    c.instructions, \n",
    "                    VectorDistance(c.contentVector,{1}) AS SimilarityScore \n",
    "                FROM c \n",
    "                ORDER BY RANK RRF \n",
    "                    (VectorDistance(c.contentVector, {1}), FullTextScore(c.description, ['{2}']))\n",
    "            '''.format(num_results, embedding, user_query)\n",
    "    \n",
    "    results = container.query_items(\n",
    "            query=query,\n",
    "            enable_cross_partition_query=True)\n",
    "\n",
    "    # Extract the necessary information from the results\n",
    "    formatted_results = []\n",
    "    for document in results:\n",
    "        score = document.pop('SimilarityScore')\n",
    "        formatted_result = {\n",
    "            'SimilarityScore': score,\n",
    "            'document': document\n",
    "        }\n",
    "        formatted_results.append(formatted_result)\n",
    "\n",
    "    return formatted_results    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Query Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.5442121841874742\n",
      "ID: 4\n",
      "Name: Chai Tea\n",
      "Similarity Score: 0.3787573327519321\n",
      "ID: 3\n",
      "Name: Baklava\n",
      "Similarity Score: 0.3714795702906132\n",
      "ID: 5\n",
      "Name: Irish Coffee\n"
     ]
    }
   ],
   "source": [
    "query = \"teas in recipe\"\n",
    "results = hybrid_search(query, 3)\n",
    "\n",
    "for document in results:\n",
    "        print(f\"Similarity Score: {document['SimilarityScore']}\")\n",
    "        print(f\"ID: {document['document']['id']}\")\n",
    "        print(f\"Name: {document['document']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query:  [{'SimilarityScore': 0.5442121841874742, 'document': {'id': '4', 'name': 'Chai Tea', 'description': 'A spiced Indian tea made with black tea, milk, and a blend of aromatic spices like cardamom, cinnamon, and ginger. Chai Tea is typically enjoyed as a warm and comforting beverage, perfect for relaxing moments or as an accompaniment to breakfast or afternoon tea.', 'cuisine': 'Indian', 'difficulty': 'Easy', 'prepTime': '5 minutes', 'cookTime': '15 minutes', 'totalTime': '20 minutes', 'servings': 2, 'ingredients': ['2 cups water', '2 cups milk', '2 tablespoons loose black tea leaves', '2 tablespoons sugar (adjust to taste)', '2-3 whole green cardamom pods, lightly crushed', '1 small piece of cinnamon stick', '1/4 teaspoon grated ginger', 'Pinch of ground cloves (optional)'], 'instructions': ['In a saucepan, add water, crushed cardamom pods, cinnamon stick, grated ginger, and ground cloves (if using). Bring it to a boil.', 'Reduce the heat to low and add the loose black tea leaves. Simmer for 3-4 minutes to infuse the flavors into the water.', 'Add milk and sugar to the saucepan. Stir well and simmer for another 5-7 minutes, allowing the tea to steep and the flavors to meld together.', 'Strain the chai tea into cups or mugs using a fine mesh strainer or tea infuser to remove the tea leaves and spices.', 'Serve the chai tea hot and enjoy its aromatic and comforting flavors.', 'You can adjust the sweetness by adding more or less sugar according to your preference.', 'Sit back, relax, and savor the deliciousness of homemade Chai Tea!']}}, {'SimilarityScore': 0.3787573327519321, 'document': {'id': '3', 'name': 'Baklava', 'description': 'A sweet pastry made of layers of flaky phyllo dough filled with chopped nuts and sweetened with syrup or honey. Baklava is a delightful dessert often enjoyed with a cup of tea or coffee, perfect for satisfying a sweet tooth.', 'cuisine': 'Turkish/Middle Eastern', 'difficulty': 'Intermediate', 'prepTime': '30 minutes', 'cookTime': '45 minutes', 'totalTime': '1 hour 15 minutes', 'servings': 20, 'ingredients': ['1 lb phyllo dough', '1 lb unsalted butter, melted', '2 cups finely chopped walnuts', '2 cups finely chopped pistachios', '1 cup granulated sugar', '1 tablespoon ground cinnamon', '1/2 teaspoon ground cloves', '1 cup water', '1 cup honey', '1 tablespoon lemon juice'], 'instructions': ['Preheat the oven to 350°F (175°C). Grease a 9x13-inch baking dish.', 'In a medium bowl, combine the chopped walnuts, pistachios, sugar, cinnamon, and ground cloves. Mix well and set aside.', 'Unroll the phyllo dough and place a damp cloth over it to prevent drying out.', 'Place one sheet of phyllo dough into the baking dish and brush it generously with melted butter. Repeat this step with 7 more sheets, brushing each layer with butter.', 'Sprinkle a generous amount of the nut mixture over the buttered phyllo layers.', 'Continue layering phyllo sheets and brushing with butter between each layer, alternating with layers of the nut mixture, until all the nut mixture is used. Reserve a few sheets of phyllo for the top layer.', 'Place the reserved sheets of phyllo on top, brushing each layer with butter.', 'Using a sharp knife, cut the baklava into diamond or square shapes.', 'Bake in the preheated oven for 45 minutes, or until the baklava turns golden brown and crispy.', 'While the baklava is baking, prepare the syrup by combining water, honey, and lemon juice in a saucepan. Bring it to a boil and then simmer for 10 minutes. Remove from heat and let it cool.', 'Once the baklava is cooked, remove it from the oven and immediately pour the cooled syrup over the hot baklava, ensuring it seeps into all the cuts.', 'Allow the baklava to cool completely in the dish before serving. This will allow it to soak up the syrup and develop its signature sticky texture.', 'Serve at room temperature and enjoy!']}}, {'SimilarityScore': 0.3714795702906132, 'document': {'id': '5', 'name': 'Irish Coffee', 'description': 'A delightful blend of hot coffee, Irish whiskey, sugar, and topped with whipped cream. Irish Coffee is a warming and indulgent drink, perfect for enjoying on chilly evenings or as a festive treat.', 'cuisine': 'Irish', 'difficulty': 'Easy', 'prepTime': '5 minutes', 'cookTime': '5 minutes', 'totalTime': '10 minutes', 'servings': 1, 'ingredients': ['1 cup hot brewed coffee', '1 1/2 ounces Irish whiskey', '1 tablespoon brown sugar', '2 tablespoons heavy cream', 'Whipped cream, for topping (optional)', 'Cocoa powder or ground cinnamon, for garnish (optional)'], 'instructions': ['Pour the hot brewed coffee into a preheated glass or mug.', 'Add the brown sugar to the coffee and stir until dissolved.', 'Stir in the Irish whiskey until well combined.', 'In a separate bowl, whip the heavy cream until it thickens slightly. It should still be pourable.', 'Slowly pour the whipped cream over the back of a spoon onto the coffee mixture, allowing it to float on top.', 'If desired, top with additional whipped cream and sprinkle with cocoa powder or ground cinnamon for garnish.', 'Serve the Irish Coffee hot and enjoy the rich and delightful flavors!', 'Note: Be careful while sipping the hot Irish Coffee, as the glass or mug may be hot.']}}]\n"
     ]
    }
   ],
   "source": [
    "query = \"teas in recipe\"\n",
    "results = hybrid_search(query, 3)\n",
    "print(\"Results for query: \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send query results to a language model to generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_cosmos_db_rag(query):\n",
    "    from openai import AzureOpenAI\n",
    "\n",
    "    # Azure OpenAI client\n",
    "    openai_client = AzureOpenAI(\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key)\n",
    "\n",
    "    # Provide instructions to the model\n",
    "    SYSTEM_PROMPT=\"\"\"\n",
    "    You are an AI assistant that helps users learn from the information found in the source material.\n",
    "    Answer the query using only the sources provided below.\n",
    "    Use bullets if the answer has multiple points.\n",
    "    If the answer is longer than 3 sentences, provide a summary.\n",
    "    Answer ONLY with the facts listed in the list of sources below. Cite your source when you answer the question\n",
    "    If there isn't enough information below, say you don't know.\n",
    "    Do not generate answers that don't use the sources below.\n",
    "    Query: {query}\n",
    "    Sources:\\n{sources}\n",
    "    \"\"\"\n",
    "\n",
    "    results = hybrid_search(query, 5)\n",
    "\n",
    "    # Use a unique separator to make the sources distinct. \n",
    "    # We chose repeated equal signs (=) followed by a newline because it's unlikely the source documents contain this sequence.\n",
    "    sources_formatted = \"=================\\n\".join(\n",
    "    [f'''Name: {document['document']['name']}, \n",
    "    Description: {document['document']['description']}, \n",
    "    Cuisine: {document['document']['cuisine']},\n",
    "    Difficulty: {document['document']['difficulty']},\n",
    "    Preparation Time: {document['document']['prepTime']},\n",
    "    Cooking Time: {document['document']['cookTime']},\n",
    "    Total Time: {document['document']['totalTime']},\n",
    "    Servings: {document['document']['servings']},\n",
    "    Ingredients: {document['document']['ingredients']},\n",
    "    Instructions: {document['document']['instructions']}'''\n",
    "    for document in results])\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": SYSTEM_PROMPT.format(query=query, sources=sources_formatted)\n",
    "            }\n",
    "        ],\n",
    "        model=azure_openai_deployment\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recipes that use sugar are:\n",
      "\n",
      "- **Chocolate Chip Cookies**: The ingredients include 3/4 cup granulated sugar and 3/4 cup brown sugar (source: Chocolate Chip Cookies).\n",
      "- **Baklava**: The ingredients include 1 cup granulated sugar (source: Baklava).\n",
      "- **Tiramisu**: The ingredients include 3/4 cup granulated sugar (source: Tiramisu).\n",
      "- **Pancakes**: The ingredients include 2 tablespoons granulated sugar (source: Pancakes).\n"
     ]
    }
   ],
   "source": [
    "# User Query\n",
    "query = \"What of the recipes use sugar?\"\n",
    "azure_cosmos_db_rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available pastas are:\n",
      "\n",
      "- **Pasta Primavera**: Made with fresh seasonal vegetables, olive oil, and Parmesan cheese. It's a colorful, light, and healthy meal.\n",
      "- **Pesto Pasta**: Prepared with fresh basil pesto, pasta, and Parmesan cheese. It's a quick and delicious option, perfect for busy weeknights or light lunches.\n",
      "\n",
      "Citations:\n",
      "- [Pasta Primavera](#)\n",
      "- [Pesto Pasta](#)\n"
     ]
    }
   ],
   "source": [
    "# User Query\n",
    "query = \"What pastas are available?\"\n",
    "azure_cosmos_db_rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To cook pesto pasta:\n",
      "\n",
      "- **Cook the pasta**: Boil 8 oz of pasta (your choice of spaghetti, penne, etc.) according to package instructions until al dente. Drain and set aside.\n",
      "- **Prepare the pesto**: In a food processor, combine 1 cup fresh basil leaves, 1/4 cup pine nuts (or walnuts), 1/2 cup grated Parmesan cheese, and 2 cloves garlic. Pulse until finely chopped.\n",
      "- **Mix the pesto**: With the food processor running, slowly drizzle in 1/2 cup olive oil until the mixture becomes a smooth paste. Scrape down the sides as needed. Season with salt and black pepper to taste.\n",
      "- **Combine pasta and pesto**: In a large mixing bowl, combine the cooked pasta with the pesto sauce. Toss until the pasta is evenly coated.\n",
      "- **Serve**: Serve immediately, garnished with additional grated Parmesan cheese if desired. \n",
      "\n",
      "Enjoy this delicious and aromatic Pesto Pasta! \n",
      "\n",
      "Source: Pesto Pasta\n"
     ]
    }
   ],
   "source": [
    "# User Query\n",
    "query = \"How do we cook pesto pasta?\"\n",
    "azure_cosmos_db_rag(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
