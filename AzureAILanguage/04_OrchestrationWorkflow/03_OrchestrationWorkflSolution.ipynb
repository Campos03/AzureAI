{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9b835b",
   "metadata": {},
   "source": [
    "# Orchestration Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21cc2cc",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77321b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-language-conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86b43a",
   "metadata": {},
   "source": [
    "## Load Azure Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843df002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load Azure configurations from environment variables\n",
    "# Ensure that AZURE_AI_LANGUAGE_KEY and AZURE_AI_LANGUAGE_ENDPOINT are set in your environment\n",
    "language_key = os.environ.get('AZURE_AI_LANGUAGE_KEY')\n",
    "language_endpoint = os.environ.get('AZURE_AI_LANGUAGE_ENDPOINT')\n",
    "\n",
    "# Represents the Project Name\n",
    "project_name = \"Python-Orchestration-Challenge\"\n",
    "# Represents the output model label.\n",
    "modelLabel = \"Python-Orchestration-Model-Challenge\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30eb4",
   "metadata": {},
   "source": [
    "## Create ConversationAuthoringClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fb1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.language.conversations.authoring import ConversationAuthoringClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Authenticate the client using Azure Key and Endpoint\n",
    "def authenticate_client():\n",
    "    \"\"\"\n",
    "    Authenticates the Azure ConversationAuthoringClient using the provided key and endpoint.\n",
    "\n",
    "    Returns:\n",
    "        ConversationAuthoringClient: An authenticated client for Azure Conversation Authoring.\n",
    "    \"\"\"\n",
    "    credential = AzureKeyCredential(language_key)\n",
    "    client = ConversationAuthoringClient(\n",
    "        endpoint=language_endpoint,\n",
    "        credential=credential\n",
    "    )\n",
    "    return client\n",
    "\n",
    "# Initialize the client\n",
    "conversation_authoring_client = authenticate_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6b6bf",
   "metadata": {},
   "source": [
    "## Create a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a576e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdDateTime': '2025-04-15T12:38:48Z',\n",
       " 'lastModifiedDateTime': '2025-04-15T12:38:48Z',\n",
       " 'projectKind': 'Orchestration',\n",
       " 'settings': {'confidenceThreshold': 0.0,\n",
       "  'normalizeCasing': False,\n",
       "  'augmentDiacritics': False},\n",
       " 'projectName': 'Python-Orchestration-Challenge',\n",
       " 'multilingual': False,\n",
       " 'description': 'Orchestration Workflow Challenge',\n",
       " 'language': 'en-us'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = {\n",
    "        \"language\": \"en-us\",  # The project language. This is BCP-47 representation of a language. For example, use \"en\" for English, \"en-gb\" for English (UK), \"es\" for Spanish etc. Required.\n",
    "        \"projectKind\": \"Orchestration\",  # Represents the project kind. Required. Known values are: \"Conversation\" and \"Orchestration\".\n",
    "        \"projectName\": project_name,  # The new project name. Required.\n",
    "        \"description\": \"Orchestration Workflow Challenge\",  # Optional. The project description.\n",
    "        \"multilingual\": False,  # Optional. Whether the project would be used for multiple languages or not.\n",
    "        \"settings\": {\n",
    "           \"confidenceThreshold\": 0.0,  # The threshold of the intent with the highest confidence, at which the prediction will automatically be changed to None. The value of the threshold should be between 0 and 1 inclusive. Required.\n",
    "       }\n",
    "   }\n",
    "\n",
    "conversation_authoring_client.create_project(project_name, project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759e46c",
   "metadata": {},
   "source": [
    "## Define Project Assets and Intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bb1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_project_assets = {\n",
    "    \"projectKind\": \"Orchestration\",\n",
    "    \"intents\": [\n",
    "        {\n",
    "            \"category\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Intent_CLU\",\n",
    "            \"orchestration\": {\n",
    "                \"targetProjectKind\": \"Conversation\",\n",
    "                \"conversationOrchestration\": {\n",
    "                    \"projectName\": \"CLU_Challenge\",\n",
    "                    \"deploymentName\": \"Travel_CLU\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Intent_QA\",\n",
    "            \"orchestration\": {\n",
    "                \"targetProjectKind\": \"QuestionAnswering\",\n",
    "                \"questionAnsweringOrchestration\": {\n",
    "                    \"projectName\": \"TravelFAQ\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"entities\": [],\n",
    "    \"utterances\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52e7a7",
   "metadata": {},
   "source": [
    "## Import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a21872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobId': '0a3c25f6-5875-4c1a-9e34-97cfd1d90266_638802720000000000', 'createdDateTime': '2025-04-15T12:40:43Z', 'lastUpdatedDateTime': '2025-04-15T12:40:43Z', 'expirationDateTime': '2025-04-22T12:40:43Z', 'status': 'succeeded'}\n"
     ]
    }
   ],
   "source": [
    "poller = conversation_authoring_client.begin_import_project(\n",
    "    project_name=project_name,\n",
    "    project={\n",
    "        \"assets\": exported_project_assets,\n",
    "        \"metadata\": {\n",
    "            \"projectKind\": \"Orchestration\",\n",
    "            \"settings\": {\n",
    "                \"confidenceThreshold\": 0.0,\n",
    "            },\n",
    "            \"projectName\": project_name,\n",
    "            \"multilingual\": False,\n",
    "            \"language\": \"en-us\",\n",
    "        },\n",
    "        \"projectFileVersion\": \"2022-05-01\",\n",
    "        \"stringIndexType\": \"Utf16CodeUnit\"  # Add this line to specify the StringIndexType\n",
    "    },\n",
    ")\n",
    "response = poller.result()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2962a3",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaf7c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'modelLabel': 'Python-Orchestration-Model-Challenge', 'trainingConfigVersion': '2022-05-01', 'trainingMode': 'standard', 'trainingStatus': {'percentComplete': 100, 'startDateTime': '2025-04-15T12:40:54.3641233Z', 'endDateTime': '2025-04-15T12:40:56.7044941Z', 'status': 'succeeded'}, 'evaluationStatus': {'percentComplete': 100, 'startDateTime': '2025-04-15T12:40:57.451491Z', 'endDateTime': '2025-04-15T12:41:13.1068155Z', 'status': 'succeeded'}}, 'jobId': '23c46502-f7e3-4994-804f-ceef70b31f6f_638802720000000000', 'createdDateTime': '2025-04-15T12:40:52Z', 'lastUpdatedDateTime': '2025-04-15T12:41:57Z', 'expirationDateTime': '2025-04-22T12:40:52Z', 'status': 'succeeded', 'warnings': []}\n"
     ]
    }
   ],
   "source": [
    "# JSON input template you can fill out and use as your body input.\n",
    "configuration = {\n",
    "    \"modelLabel\": modelLabel,  # Represents the output model label. Required.\n",
    "    \"trainingMode\": \"standard\",  # Represents the mode of the training operation. Required. Known values are: \"advanced\" and \"standard\".\n",
    "    \"evaluationOptions\": {\n",
    "        \"kind\": \"percentage\",  # Optional. Represents the evaluation kind. By default, the evaluation kind is set to percentage. Known values are: \"percentage\" and \"manual\".\n",
    "        \"testingSplitPercentage\": 20,  # Optional. Represents the testing dataset split percentage. Only needed in case the evaluation kind is percentage.\n",
    "        \"trainingSplitPercentage\": 80  # Optional. Represents the training dataset split percentage. Only needed in case the evaluation kind is percentage.\n",
    "    },\n",
    "    #\"trainingConfigVersion\": \"str\"  # Optional. Represents training config version. By default, \"latest\" value is used which uses the latest released training config version.\n",
    "   }\n",
    "\n",
    "poller = conversation_authoring_client.begin_train(project_name=project_name,configuration=configuration)\n",
    "response = poller.result()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045e798",
   "metadata": {},
   "source": [
    "## Display Model Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c90b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intentsEvaluation': {'confusionMatrix': {'None': {}, 'Intent_CLU': {'Intent_CLU': {'normalizedValue': 90.0, 'rawValue': 9.0}, 'Intent_QA': {'normalizedValue': 10.0, 'rawValue': 1.0}}, 'Intent_QA': {'Intent_QA': {'normalizedValue': 85.71429, 'rawValue': 6.0}, 'Intent_CLU': {'normalizedValue': 14.285714, 'rawValue': 1.0}}}, 'intents': {'Intent_CLU': {'f1': 0.8999999761581421, 'precision': 0.8999999761581421, 'recall': 0.8999999761581421, 'truePositiveCount': 9, 'trueNegativeCount': 6, 'falsePositiveCount': 1, 'falseNegativeCount': 1}, 'Intent_QA': {'f1': 0.8571428656578064, 'precision': 0.8571428656578064, 'recall': 0.8571428656578064, 'truePositiveCount': 6, 'trueNegativeCount': 9, 'falsePositiveCount': 1, 'falseNegativeCount': 1}, 'None': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'truePositiveCount': 0, 'trueNegativeCount': 0, 'falsePositiveCount': 0, 'falseNegativeCount': 0}}, 'microF1': 0.88235295, 'microPrecision': 0.88235295, 'microRecall': 0.88235295, 'macroF1': 0.8785714, 'macroPrecision': 0.8785714, 'macroRecall': 0.8785714}, 'evaluationOptions': {'kind': 'percentage', 'trainingSplitPercentage': 80, 'testingSplitPercentage': 20}}\n"
     ]
    }
   ],
   "source": [
    "evaluation_summary = conversation_authoring_client.get_model_evaluation_summary(project_name=project_name, trained_model_label=modelLabel)\n",
    "print(evaluation_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050ffe5",
   "metadata": {},
   "source": [
    "## Deploy the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1b5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deploymentName': 'Python-Orchestration-Model-Challenge', 'modelId': 'Python-Orchestration-Model-Challenge-20250415T124157-2055d755b4224cdb9165297ca62a0c89', 'lastTrainedDateTime': '2025-04-15T12:41:57.7969696Z', 'lastDeployedDateTime': '2025-04-15T12:43:23Z', 'deploymentExpirationDate': '2026-10-27', 'modelTrainingConfigVersion': '2022-05-01'}\n"
     ]
    }
   ],
   "source": [
    "deployment = {\n",
    "       \"trainedModelLabel\": modelLabel  # Represents the trained model label. Required.\n",
    "   }\n",
    "\n",
    "trained_model = conversation_authoring_client.begin_deploy_project(project_name=project_name, deployment_name=modelLabel, deployment=deployment)\n",
    "response = trained_model.result()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9db5e8",
   "metadata": {},
   "source": [
    "## Making the Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e1abc",
   "metadata": {},
   "source": [
    "\n",
    "## Create a ConversationAnalysisClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5548f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.language.conversations import ConversationAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "credential = AzureKeyCredential(language_key)\n",
    "conversation_analysis_client = ConversationAnalysisClient(\n",
    "        endpoint=language_endpoint,\n",
    "        credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557bf355",
   "metadata": {},
   "source": [
    "## Helper function to Send requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa23f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(result):\n",
    "    \"\"\"\n",
    "    Processes and displays the result of an analyzed conversation.\n",
    "\n",
    "    This function takes the result of a conversation analysis and extracts\n",
    "    relevant information such as the top intent, project kind, and details\n",
    "    about specific intents (e.g., Intent_CLU or Intent_QA). It prints the\n",
    "    extracted information in a readable format.\n",
    "\n",
    "    Args:\n",
    "        result (dict): The result of the conversation analysis, typically\n",
    "                       returned by the Azure ConversationAnalysisClient.\n",
    "\n",
    "    Returns:\n",
    "        None: The function prints the result details to the console.\n",
    "    \"\"\"\n",
    "    # Check if the result is of type 'ConversationResult'\n",
    "    if result.get('kind') == 'ConversationResult':\n",
    "        prediction = result['result']['prediction']\n",
    "        query = result['result']['query']\n",
    "        top_intent = prediction['topIntent']\n",
    "        project_kind = prediction['projectKind']\n",
    "\n",
    "        # Print basic information about the query and prediction\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Top Intent: {top_intent}\")\n",
    "        print(f\"Project Kind: {project_kind}\")\n",
    "\n",
    "        # Handle details for the 'Intent_CLU' intent\n",
    "        if top_intent == 'Intent_CLU':\n",
    "            intent_details = prediction['intents']['Intent_CLU']\n",
    "            print(f\"\\nIntent_CLU Details:\")\n",
    "            print(f\"  Confidence Score: {intent_details['confidenceScore']}\")\n",
    "            if 'result' in intent_details:\n",
    "                sub_prediction = intent_details['result']['prediction']\n",
    "                print(f\"  Sub-Intent: {sub_prediction['topIntent']}\")\n",
    "                print(\"  Sub-Intent Confidence Scores:\")\n",
    "                for sub_intent in sub_prediction['intents']:\n",
    "                    print(f\"    - {sub_intent['category']}: {sub_intent['confidenceScore']}\")\n",
    "                print(\"\\nEntities:\")\n",
    "                for entity in sub_prediction['entities']:\n",
    "                    print(f\"  - {entity['category']}: {entity['text']}\")\n",
    "                    print(f\"    Confidence Score: {entity['confidenceScore']}\")\n",
    "                    if 'resolutions' in entity:\n",
    "                        print(f\"    Resolutions: {entity['resolutions']}\")\n",
    "                    if 'extraInformation' in entity:\n",
    "                        print(f\"    Extra Information: {entity['extraInformation']}\")\n",
    "\n",
    "        # Handle details for the 'Intent_QA' intent\n",
    "        elif top_intent == 'Intent_QA':\n",
    "            intent_details = prediction['intents']['Intent_QA']\n",
    "            print(f\"\\nIntent_QA Details:\")\n",
    "            print(f\"  Confidence Score: {intent_details['confidenceScore']}\")\n",
    "            if 'result' in intent_details:\n",
    "                answers = intent_details['result']['answers']\n",
    "                print(\"\\nAnswers:\")\n",
    "                for answer in answers:\n",
    "                    print(f\"  - Answer: {answer['answer']}\")\n",
    "                    print(f\"    Confidence Score: {answer['confidenceScore']}\")\n",
    "                    print(f\"    Source: {answer['source']}\")\n",
    "                    print(f\"    Questions: {answer['questions']}\")\n",
    "                    if 'metadata' in answer:\n",
    "                        print(f\"    Metadata: {answer['metadata']}\")\n",
    "                    if 'dialog' in answer:\n",
    "                        print(f\"    Dialog Prompts:\")\n",
    "                        for prompt in answer['dialog']['prompts']:\n",
    "                            print(f\"      - {prompt['displayText']} (ID: {prompt['qnaId']})\")\n",
    "\n",
    "        # Handle cases where no relevant intent is found\n",
    "        else:\n",
    "            print(\"\\nNo relevant intent found.\")\n",
    "\n",
    "    # Handle invalid result formats\n",
    "    else:\n",
    "        print(\"Invalid result format.\")\n",
    "\n",
    "def analyze_utterance(utterance):\n",
    "    \"\"\"\n",
    "    Analyzes the given utterance using the deployed Azure AI Language model.\n",
    "\n",
    "    This function sends the provided utterance to the Azure ConversationAnalysisClient\n",
    "    for analysis. It uses the deployed model to predict the intent and entities\n",
    "    associated with the utterance.\n",
    "\n",
    "    Args:\n",
    "        utterance (str): The text input to analyze.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the result of the analysis to the console.\n",
    "    \"\"\"\n",
    "    # Send the utterance to the Azure ConversationAnalysisClient for analysis\n",
    "    result = conversation_analysis_client.analyze_conversation(\n",
    "        task={\n",
    "            \"kind\": \"Conversation\",  # Specify the task type as \"Conversation\"\n",
    "            \"analysisInput\": {\n",
    "                \"conversationItem\": {\n",
    "                    \"participantId\": \"1\",  # Identifier for the participant\n",
    "                    \"id\": \"1\",  # Identifier for the conversation\n",
    "                    \"modality\": \"text\",  # Specify the modality as text\n",
    "                    \"language\": \"en\",  # Language of the utterance\n",
    "                    \"text\": utterance  # The utterance to analyze\n",
    "                },\n",
    "                \"isLoggingEnabled\": False  # Disable logging for privacy\n",
    "            },\n",
    "            \"parameters\": {\n",
    "                \"projectName\": project_name,  # Name of the deployed project\n",
    "                \"deploymentName\": modelLabel,  # Name of the deployed model\n",
    "                \"verbose\": True  # Enable verbose output for detailed results\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print the result of the analysis\n",
    "    display_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbc72c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I'd like to book 2 flight tickets to London and 2 rooms for the Strand Palace Hotel on Oct 15.\n",
      "Top Intent: Intent_CLU\n",
      "Project Kind: Orchestration\n",
      "\n",
      "Intent_CLU Details:\n",
      "  Confidence Score: 0.88208646\n",
      "  Sub-Intent: Book\n",
      "  Sub-Intent Confidence Scores:\n",
      "    - Book: 0.90206134\n",
      "    - Cancel: 0.79849505\n",
      "    - None: 0.7231303\n",
      "\n",
      "Entities:\n",
      "  - NumOfTickets: 2 flight tickets\n",
      "    Confidence Score: 1\n",
      "  - Location: London\n",
      "    Confidence Score: 1\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'geography.location'}]\n",
      "  - NumOfRooms: 2 rooms\n",
      "    Confidence Score: 1\n",
      "  - Hotel: the Strand Palace Hotel\n",
      "    Confidence Score: 1\n",
      "  - Location: Strand Palace Hotel\n",
      "    Confidence Score: 1\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'geography.location'}]\n",
      "  - Date: Oct 15\n",
      "    Confidence Score: 1\n",
      "    Resolutions: [{'resolutionKind': 'DateTimeResolution', 'dateTimeSubKind': 'Date', 'timex': 'XXXX-10-15', 'value': '2024-10-15'}, {'resolutionKind': 'DateTimeResolution', 'dateTimeSubKind': 'Date', 'timex': 'XXXX-10-15', 'value': '2025-10-15'}]\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'datetime.date'}]\n"
     ]
    }
   ],
   "source": [
    "# Sample utterance to analyze\n",
    "utterance = \"I'd like to book 2 flight tickets to London and 2 rooms for the Strand Palace Hotel on Oct 15.\"\n",
    "analyze_utterance(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eeea6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Contoso Travel?\n",
      "Top Intent: Intent_QA\n",
      "Project Kind: Orchestration\n",
      "\n",
      "Intent_QA Details:\n",
      "  Confidence Score: 0.9148873\n",
      "\n",
      "Answers:\n",
      "  - Answer: Contoso Travel is a company that has been meeting the needs of business travelers since 2001. They aim to make travel as easy as possible for their clients.\n",
      "    Confidence Score: 1.0\n",
      "    Source: TravelFAQ.docx\n",
      "    Questions: ['What is Contoso Travel?']\n",
      "    Metadata: {'system_metadata_qna_edited_manually': 'true'}\n",
      "    Dialog Prompts:\n",
      "      - Support (ID: 68)\n",
      "      - Contact (ID: 52)\n"
     ]
    }
   ],
   "source": [
    "# Sample utterance to analyze\n",
    "utterance = \"What is Contoso Travel?\"\n",
    "analyze_utterance(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5638cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Reserve me 2 rooms at the Hilton in Seattle for 2 nights this June 20.\n",
      "Top Intent: Intent_CLU\n",
      "Project Kind: Orchestration\n",
      "\n",
      "Intent_CLU Details:\n",
      "  Confidence Score: 0.8362664\n",
      "  Sub-Intent: Book\n",
      "  Sub-Intent Confidence Scores:\n",
      "    - Book: 0.87660927\n",
      "    - Cancel: 0.7009587\n",
      "    - None: 0.54180986\n",
      "\n",
      "Entities:\n",
      "  - NumOfRooms: 2 rooms\n",
      "    Confidence Score: 1\n",
      "  - Hotel: the Hilton\n",
      "    Confidence Score: 1\n",
      "  - Location: Seattle\n",
      "    Confidence Score: 1\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'geography.location'}]\n",
      "  - Date: 2 nights\n",
      "    Confidence Score: 1\n",
      "    Resolutions: [{'resolutionKind': 'TemporalSpanResolution', 'timex': 'P2D', 'duration': 'P2D'}]\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'datetime.duration'}]\n",
      "  - Date: this June 20\n",
      "    Confidence Score: 1\n",
      "    Resolutions: [{'resolutionKind': 'DateTimeResolution', 'dateTimeSubKind': 'Date', 'timex': 'XXXX-06-20', 'value': '2025-06-20'}]\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'datetime.date'}]\n"
     ]
    }
   ],
   "source": [
    "# Sample utterance to analyze\n",
    "utterance = \"Reserve me 2 rooms at the Hilton in Seattle for 2 nights this June 20.\"\n",
    "analyze_utterance(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77fae4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Cancel my reservation for 2 rooms at the Hilton in Seattle for 2 nights this June 20.\n",
      "Top Intent: Intent_CLU\n",
      "Project Kind: Orchestration\n",
      "\n",
      "Intent_CLU Details:\n",
      "  Confidence Score: 0.9170737\n",
      "  Sub-Intent: Cancel\n",
      "  Sub-Intent Confidence Scores:\n",
      "    - Cancel: 0.9085631\n",
      "    - Book: 0.69098586\n",
      "    - None: 0.53636175\n",
      "\n",
      "Entities:\n",
      "  - NumOfRooms: 2 rooms\n",
      "    Confidence Score: 1\n",
      "  - Hotel: the Hilton\n",
      "    Confidence Score: 1\n",
      "  - Location: Seattle\n",
      "    Confidence Score: 1\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'geography.location'}]\n",
      "  - Date: 2 nights\n",
      "    Confidence Score: 1\n",
      "    Resolutions: [{'resolutionKind': 'TemporalSpanResolution', 'timex': 'P2D', 'duration': 'P2D'}]\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'datetime.duration'}]\n",
      "  - Date: this June 20\n",
      "    Confidence Score: 1\n",
      "    Resolutions: [{'resolutionKind': 'DateTimeResolution', 'dateTimeSubKind': 'Date', 'timex': 'XXXX-06-20', 'value': '2025-06-20'}]\n",
      "    Extra Information: [{'extraInformationKind': 'EntitySubtype', 'value': 'datetime.date'}]\n"
     ]
    }
   ],
   "source": [
    "# Sample utterance to analyze\n",
    "utterance = \"Cancel my reservation for 2 rooms at the Hilton in Seattle for 2 nights this June 20.\"\n",
    "analyze_utterance(utterance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
