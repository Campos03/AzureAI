{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de50391c",
   "metadata": {},
   "source": [
    "# Agentic RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9304e",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c182706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "azure_openai_api_version = \"2024-10-01-preview\"\n",
    "azure_openai_embedding_size = 1536\n",
    "\n",
    "azure_cosmosdb_endpoint = os.getenv(\"AZURE_COSMOSDB_ENDPOINT\")\n",
    "azure_cosmosdb_key = os.getenv(\"AZURE_COSMOSDB_KEY\")\n",
    "\n",
    "azure_search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "azure_search_service_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22655d58",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61d4617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from typing import Annotated\n",
    "from openai import AzureOpenAI\n",
    "from azure.cosmos import CosmosClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "class RAGPlugin:\n",
    "    \"\"\"A plugin that gets data from multiple sources.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides information about recipes and cooking\")\n",
    "    def get_recipes(self, \n",
    "        user_query: Annotated[str, \"The user query\"]) -> Annotated[str, \"Returns the recipes or cooking information.\"]:\n",
    "        \n",
    "        # Setup the connection\n",
    "        azure_cosmosdb_database = \"recipes-database\"\n",
    "        azure_cosmosdb_container = \"recipes-container\"\n",
    "        cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "        database = cosmos_client.get_database_client(azure_cosmosdb_database)\n",
    "        container = database.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "        # Azure OpenAI client\n",
    "        openai_client = AzureOpenAI(\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        azure_deployment=azure_openai_embeddings_deployment,\n",
    "        api_key=azure_openai_key)\n",
    "\n",
    "        # get embedding of user query\n",
    "        response = openai_client.embeddings.create(input=user_query, \n",
    "                                                model=azure_openai_embeddings_deployment, \n",
    "                                                dimensions=azure_openai_embedding_size)\n",
    "        embedding = response.data[0].embedding\n",
    "\n",
    "        # format the query\n",
    "        query ='''\n",
    "                    SELECT TOP {0} \n",
    "                        c.id, \n",
    "                        c.name,\n",
    "                        c.description,\n",
    "                        c.cuisine,\n",
    "                        c.difficulty,\n",
    "                        c.prepTime,\n",
    "                        c.cookTime,\n",
    "                        c.totalTime,\n",
    "                        c.servings,\n",
    "                        c.ingredients,\n",
    "                        c.instructions, \n",
    "                        VectorDistance(c.contentVector,{1}) AS SimilarityScore \n",
    "                    FROM c \n",
    "                    ORDER BY RANK RRF \n",
    "                        (VectorDistance(c.contentVector, {1}), FullTextScore(c.description, ['{2}']))\n",
    "                '''.format(5, embedding, user_query)\n",
    "        \n",
    "        results = container.query_items(\n",
    "                query=query,\n",
    "                enable_cross_partition_query=True)\n",
    "        \n",
    "        items = [item for item in results]\n",
    "\n",
    "        return items\n",
    "    \n",
    "    @kernel_function(description=\"Provides information about tech related stuff like Azure\")\n",
    "    def get_azure_services(self, \n",
    "        user_query: Annotated[str, \"The user query\"]) -> Annotated[str, \"Returns the Azure services or tech related information.\"]:\n",
    "        \n",
    "        # Setup the connection\n",
    "        azure_cosmosdb_database = \"azureservicesdatabase01\"\n",
    "        azure_cosmosdb_container = \"azureservicescontainer01\"\n",
    "        cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "        database = cosmos_client.get_database_client(azure_cosmosdb_database)\n",
    "        container = container = database.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "        # Azure OpenAI client\n",
    "        openai_client = AzureOpenAI(\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        azure_deployment=azure_openai_embeddings_deployment,\n",
    "        api_key=azure_openai_key)\n",
    "\n",
    "        response = openai_client.embeddings.create(input=user_query, \n",
    "                                                model=azure_openai_embeddings_deployment, \n",
    "                                                dimensions=1536)\n",
    "        embedding = response.data[0].embedding\n",
    "\n",
    "\n",
    "        # Build the query with str.format() method\n",
    "        query = '''\n",
    "            SELECT TOP {0} c.id, c.title, c.category, c.content\n",
    "            FROM c\n",
    "            ORDER BY RANK RRF \n",
    "                (VectorDistance(c.contentVector, {1}), FullTextScore(c.title, ['{2}']))\n",
    "        '''.format(5, embedding, user_query)\n",
    "\n",
    "        results = container.query_items(\n",
    "                query=query,\n",
    "                enable_cross_partition_query=True)\n",
    "        \n",
    "        items = [item for item in results]\n",
    "\n",
    "        return items\n",
    "    \n",
    "    @kernel_function(description=\"Provides information about NASA related stuff and geography\")\n",
    "    def get_geography_information(self, \n",
    "        user_query: Annotated[str, \"The user query\"]) -> Annotated[str, \"Returns the information about NASA or geography.\"]:\n",
    "        \n",
    "        # index name\n",
    "        azure_search_service_index_name = \"ai-search-index-001\"\n",
    "\n",
    "        # User Query\n",
    "        query = user_query\n",
    "\n",
    "        # Get credential from Azure AI Search Admin key\n",
    "        credential = AzureKeyCredential(azure_search_service_admin_key)\n",
    "        search_client = SearchClient(endpoint=azure_search_service_endpoint, \n",
    "                                    credential=credential, \n",
    "                                    index_name=azure_search_service_index_name)\n",
    "\n",
    "        # Convert query into vector form\n",
    "        vector_query = VectorizableTextQuery(text=query, \n",
    "                                            k_nearest_neighbors=50, \n",
    "                                            fields=\"text_vector\",\n",
    "                                            weight=1)\n",
    "\n",
    "        results = search_client.search(\n",
    "            query_type=\"semantic\", \n",
    "            semantic_configuration_name='my-semantic-config',\n",
    "            search_text=query,\n",
    "            vector_queries= [vector_query],\n",
    "            select=[\"title\",\"chunk\",\"locations\"],\n",
    "            top=5,\n",
    "        )\n",
    "\n",
    "        sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}, LOCATIONS: {document[\"locations\"]}' for document in results])\n",
    "        return sources_formatted\n",
    "    \n",
    "    @kernel_function(description=\"Provides information travel related products\")\n",
    "    def get_travel_products(self, \n",
    "        user_query: Annotated[str, \"The user query\"]) -> Annotated[str, \"Returns the information about travel related products.\"]:\n",
    "        \n",
    "        # index name\n",
    "        azure_search_service_index_name = \"product-index-challenge\"\n",
    "\n",
    "        # User Query\n",
    "        query = user_query\n",
    "\n",
    "        # Get credential from Azure AI Search Admin key\n",
    "        credential = AzureKeyCredential(azure_search_service_admin_key)\n",
    "        search_client = SearchClient(endpoint=azure_search_service_endpoint, \n",
    "                                    credential=credential, \n",
    "                                    index_name=azure_search_service_index_name)\n",
    "\n",
    "        # Convert query into vector form\n",
    "        vector_query = VectorizableTextQuery(text=query, \n",
    "                                            k_nearest_neighbors=50, \n",
    "                                            fields=\"text_vector\",\n",
    "                                            weight=1)\n",
    "\n",
    "        results = search_client.search(\n",
    "            query_type=\"semantic\", \n",
    "            semantic_configuration_name='my-semantic-config',\n",
    "            search_text=query,\n",
    "            vector_queries= [vector_query],\n",
    "            select=[\"title\",\"chunk\"],\n",
    "            top=5,\n",
    "        )\n",
    "\n",
    "        # Use a unique separator to make the sources distinct. \n",
    "        # We chose repeated equal signs (=) followed by a newline because it's unlikely the source documents contain this sequence.\n",
    "        sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}' for document in results])\n",
    "\n",
    "        return sources_formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba931cab",
   "metadata": {},
   "source": [
    "## Agent Definition and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5435d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# Create the instance of the Kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the AzureChatCompletion AI Service to the Kernel\n",
    "azure_service_id = \"azure\"\n",
    "kernel.add_service(AzureChatCompletion(service_id=azure_service_id))\n",
    "\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=azure_service_id)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(RAGPlugin(), plugin_name=\"RAGPlugin\")\n",
    "\n",
    "# Create the agent\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel, \n",
    "    name=\"RAGAgent\", \n",
    "    instructions=\"\"\"\n",
    "        Answer questions about information related to the datasources you have access to.\n",
    "        You will always provide the source of the information by displaying the name or title of the document source.\n",
    "    \"\"\", \n",
    "    arguments=KernelArguments(\n",
    "        settings=settings,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Start by creating a ChatHistoryAgentThread object to maintain the conversation state\n",
    "thread: ChatHistoryAgentThread = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e8efc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **prep time for Bruschetta** is approximately 15 minutes.\n",
      "\n",
      "### How to Prepare Bruschetta\n",
      "\n",
      "#### Ingredients:\n",
      "- 4 slices of crusty Italian bread\n",
      "- 2 ripe tomatoes, diced\n",
      "- 1/4 cup fresh basil leaves, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 2 tablespoons extra-virgin olive oil\n",
      "- 1 tablespoon balsamic vinegar\n",
      "- Salt, to taste\n",
      "- Black pepper, to taste\n",
      "\n",
      "#### Instructions:\n",
      "1. Preheat the oven to 375°F (190°C).\n",
      "2. Place the slices of bread on a baking sheet and drizzle them with olive oil. Toast in the preheated oven for about 8-10 minutes, or until the bread is crispy and golden brown.\n",
      "3. In a bowl, combine the diced tomatoes, minced garlic, chopped basil leaves, olive oil, and balsamic vinegar. Mix well to combine all the ingredients.\n",
      "4. Season the tomato mixture with salt and black pepper according to taste. Stir well.\n",
      "5. Remove the toasted bread from the oven and let it cool slightly. Rub each slice with a clove of garlic to infuse the bread with its flavor.\n",
      "6. Spoon the tomato mixture generously onto each slice of bread, spreading it evenly.\n",
      "7. Drizzle a little extra olive oil on top of the bruschetta for added flavor, if desired.\n",
      "8. Serve the bruschetta immediately as an appetizer or light snack.\n",
      "\n",
      "**Total Time**: 25 minutes\n",
      "\n",
      "Enjoy the fresh and vibrant flavors of this classic Italian appetizer!\n",
      "\n",
      "**Source**: Recipe document\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the prep time for Bruschetta and how do you prepare it?\"\n",
    "async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "    print(f\"{response.content}\")\n",
    "    thread = response.thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28d404db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Azure Firewall** is a managed, cloud-based network security service designed to protect your Azure Virtual Network resources. \n",
      "\n",
      "### Key Features:\n",
      "- **Stateful Packet Inspection**: Monitors the state and context of active connections, making it possible to filter traffic based on state, port, and protocol.\n",
      "- **Application Filtering**: Allows for the control of outbound HTTP/S traffic based on categories and can prevent unauthorized applications from communicating.\n",
      "- **Threat Intelligence**: Identifies and blocks known malicious IP addresses using threat intelligence feeds.\n",
      "- **Support for Various Network Protocols**: Handles TCP, UDP, and ICMP traffic, making it versatile for different network scenarios.\n",
      "\n",
      "### Integration and Use:\n",
      "- **Network Security Policies**: Creates and enforces policies to manage and restrict network traffic, thus enhancing security.\n",
      "- **Unauthorized Access Prevention**: Ensures that only authorized traffic is allowed through the network, protecting applications and data.\n",
      "- **Integration with other Azure Services**: Works seamlessly with Azure Monitor and Azure Security Center for comprehensive monitoring and security management.\n",
      "\n",
      "Azure Firewall is essential for managing network security and maintaining robust protection for applications and data in the Azure cloud.\n",
      "\n",
      "**Source**: Azure Firewall document\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is Azure Firewall?\"\n",
    "async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "    print(f\"{response.content}\")\n",
    "    thread = response.thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1753480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Arctic Ocean, you can witness several unique and fascinating phenomena:\n",
      "\n",
      "### Ice Features:\n",
      "- **Sea Ice**: Large expanses of floating ice cover much of the Arctic Ocean, with intricate patterns of wavy tendrils formed by newly created thin sea ice.\n",
      "- **Cloud Streets**: These are parallel rows of clouds formed by winds blowing from the cold ice surface over the warmer, moister air near the open ocean. They are visible due to the spinning air cylinders that develop, creating areas of cloud formation and clear skies in a repeating pattern.\n",
      "\n",
      "### Scenic Views:\n",
      "- **Snow and Ice-Covered Landscapes**: The Arctic Ocean is surrounded by snow and ice, particularly in the easternmost reaches of Russia, contributing to its vast, white, frozen wilderness.\n",
      "\n",
      "These features make the Arctic Ocean a visually captivating and scientifically significant region.\n",
      "\n",
      "**Source**: Document page-21\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What can you see in the Arctic Ocean?\"\n",
    "async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "    print(f\"{response.content}\")\n",
    "    thread = response.thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85da656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the **TrailMaster X4 Tent** is **$250**.\n",
      "\n",
      "**Source**: Product Information Document\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the price of the TrailMaster X4 Tent?\"\n",
    "async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "    print(f\"{response.content}\")\n",
    "    thread = response.thread"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
