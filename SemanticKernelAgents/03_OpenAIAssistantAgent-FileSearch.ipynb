{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel OpenAI Assistant Agent File Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['page-49.pdf', 'page-161.pdf', 'page-151.pdf', 'page-129.pdf', 'page-165.pdf', 'page-11.pdf', 'page-115.pdf', 'page-23.pdf', 'page-105.pdf', 'page-159.pdf', 'page-141.pdf', 'page-81.pdf', 'page-167.pdf', 'page-155.pdf', 'page-73.pdf', 'page-15.pdf', 'page-21.pdf', 'page-65.pdf', 'page-131.pdf', 'page-35.pdf', 'page-171.pdf', 'page-9.pdf', 'page-94.pdf', 'page-77.pdf', 'page-157.pdf', 'page-7.pdf', 'page-31.pdf', 'page-85.pdf', 'page-117.pdf', 'page-61.pdf', 'page-101.pdf', 'page-91.pdf', 'page-123.pdf', 'page-57.pdf', 'page-127.pdf', 'page-51.pdf', 'page-55.pdf', 'page-95.pdf', 'page-45.pdf', 'page-133.pdf', 'page-39.pdf', 'page-83.pdf', 'page-87.pdf', 'page-67.pdf', 'page-119.pdf', 'page-8.pdf', 'page-134.pdf', 'page-173.pdf', 'page-153.pdf', 'page-125.pdf', 'page-59.pdf', 'page-33.pdf', 'page-89.pdf', 'page-121.pdf', 'page-163.pdf', 'page-169.pdf', 'page-79.pdf', 'page-69.pdf', 'page-19.pdf', 'page-41.pdf', 'page-145.pdf', 'page-137.pdf', 'page-17.pdf', 'page-135.pdf', 'page-13.pdf', 'page-168.pdf', 'page-109.pdf', 'page-178.pdf', 'page-27.pdf', 'page-71.pdf', 'page-75.pdf', 'page-43.pdf', 'page-63.pdf', 'page-25.pdf', 'page-111.pdf', 'page-139.pdf', 'page-147.pdf', 'page-143.pdf', 'page-93.pdf', 'page-107.pdf', 'page-99.pdf', 'page-103.pdf', 'page-176.pdf', 'page-175.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_directory = \"../Data/nasabooks\"\n",
    "\n",
    "def get_filepath_for_filename(filename: str) -> str:\n",
    "    base_directory = file_directory\n",
    "    return os.path.join(base_directory, filename)\n",
    "\n",
    "# List all files in the directory\n",
    "base_directory = file_directory\n",
    "try:\n",
    "    filenames = os.listdir(base_directory)\n",
    "    print(filenames)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory '{base_directory}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-2: Create an Agent and Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents.open_ai.azure_assistant_agent import AzureAssistantAgent\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.annotation_content import AnnotationContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "# Step 1: Create an assistant agent\n",
    "agent = await AzureAssistantAgent.create(\n",
    "        kernel=Kernel(),\n",
    "        service_id=\"agent\",\n",
    "        name=\"SK_OpenAI_Assistant_Agent_File_Search\",\n",
    "        instructions=\"\"\"\n",
    "            The document store contains pages from a Nasa book.\n",
    "            Always analyze the document store to provide an answer to the user's question.\n",
    "            Never rely on your knowledge of information not included in the document store.\n",
    "            Always format response using markdown.\n",
    "            \"\"\",\n",
    "        enable_file_search=True,\n",
    "        vector_store_filenames=[get_filepath_for_filename(filename) for filename in filenames],\n",
    "    )\n",
    "\n",
    "# Step 2: Create a thread\n",
    "thread_id = await agent.create_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3-6: \n",
    "3. Add a message to the thread\n",
    "4. Run the Assistant\n",
    "5. Display the Assistant's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What can I see in the United States?\"\n",
    "\n",
    "# STEP 3: Add a user question to the thread\n",
    "await agent.add_chat_message(\n",
    "        thread_id=thread_id, \n",
    "        message=ChatMessageContent(role=AuthorRole.USER, content=user_question)\n",
    ")\n",
    "\n",
    "footnotes: list[AnnotationContent] = []\n",
    "\n",
    "# STEP 4: Invoke the agent to get a response\n",
    "async for response in agent.invoke(thread_id=thread_id):\n",
    "    footnotes.extend([item for item in response.items if isinstance(item, AnnotationContent)])\n",
    "    #STEP 5: Print the Assistant response\n",
    "    print(f\"{response.content}\", end=\"\", flush=True)\n",
    "\n",
    "print()\n",
    "\n",
    "if len(footnotes) > 0:\n",
    "    for footnote in footnotes:\n",
    "        print(\n",
    "            f\"\\n`{footnote.quote}` => {footnote.file_id} \"\n",
    "            f\"(Index: {footnote.start_index} - {footnote.end_index})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the response\n",
    "print(\"Value:\")\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "print(\"Annotations:\")\n",
    "annotations = [item for item in response.items if isinstance(item, AnnotationContent)]\n",
    "for annotation in annotations:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat citations with the proper filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def reformat_citations(response):\n",
    "    # Extract the annotations\n",
    "    annotations = [item for item in response.items if isinstance(item, AnnotationContent)]\n",
    "    \n",
    "    # Original response\n",
    "    paragraph = response.content\n",
    "    \n",
    "    # Dictionary to store key-value pairs of text and filename\n",
    "    text_filename_pairs = {}\n",
    "\n",
    "    # Iterate over the annotations and extract the relevant information\n",
    "    for annotation in annotations:\n",
    "        file_id = annotation.file_id\n",
    "        text = annotation.quote\n",
    "        # Retrieve the filename from the file_id\n",
    "        cited_file = await agent.client.files.retrieve(file_id)\n",
    "        filename = cited_file.filename\n",
    "\n",
    "        if text not in text_filename_pairs:\n",
    "            text_filename_pairs[text] = []\n",
    "        text_filename_pairs[text].append(filename)\n",
    "\n",
    "    # Replace the citation texts with their corresponding filenames prefixed with \" Source: \"\n",
    "    for text, filenames in text_filename_pairs.items():\n",
    "        sources = \" Source: \" + \", \".join(filenames)\n",
    "        paragraph = paragraph.replace(text, sources)\n",
    "\n",
    "    return paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(await reformat_citations(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Files, Thread, Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent is not None:\n",
    "    [await agent.delete_file(file_id) for file_id in agent.file_search_file_ids]\n",
    "    await agent.delete_thread(thread_id)\n",
    "    await agent.delete()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
