{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel OpenAI Assistant Agent File Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['page-49.pdf', 'page-161.pdf', 'page-151.pdf', 'page-129.pdf', 'page-165.pdf', 'page-11.pdf', 'page-115.pdf', 'page-23.pdf', 'page-105.pdf', 'page-159.pdf', 'page-141.pdf', 'page-81.pdf', 'page-167.pdf', 'page-155.pdf', 'page-73.pdf', 'page-15.pdf', 'page-21.pdf', 'page-65.pdf', 'page-131.pdf', 'page-35.pdf', 'page-171.pdf', 'page-9.pdf', 'page-94.pdf', 'page-77.pdf', 'page-157.pdf', 'page-7.pdf', 'page-31.pdf', 'page-85.pdf', 'page-117.pdf', 'page-61.pdf', 'page-101.pdf', 'page-91.pdf', 'page-123.pdf', 'page-57.pdf', 'page-127.pdf', 'page-51.pdf', 'page-55.pdf', 'page-95.pdf', 'page-45.pdf', 'page-133.pdf', 'page-39.pdf', 'page-83.pdf', 'page-87.pdf', 'page-67.pdf', 'page-119.pdf', 'page-8.pdf', 'page-134.pdf', 'page-173.pdf', 'page-153.pdf', 'page-125.pdf', 'page-59.pdf', 'page-33.pdf', 'page-89.pdf', 'page-121.pdf', 'page-163.pdf', 'page-169.pdf', 'page-79.pdf', 'page-69.pdf', 'page-19.pdf', 'page-41.pdf', 'page-145.pdf', 'page-137.pdf', 'page-17.pdf', 'page-135.pdf', 'page-13.pdf', 'page-168.pdf', 'page-109.pdf', 'page-178.pdf', 'page-27.pdf', 'page-71.pdf', 'page-75.pdf', 'page-43.pdf', 'page-63.pdf', 'page-25.pdf', 'page-111.pdf', 'page-139.pdf', 'page-147.pdf', 'page-143.pdf', 'page-93.pdf', 'page-107.pdf', 'page-99.pdf', 'page-103.pdf', 'page-176.pdf', 'page-175.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_directory = \"../Data/nasabooks\"\n",
    "\n",
    "# List all files in the directory\n",
    "try:\n",
    "    filenames = os.listdir(file_directory)\n",
    "    print(filenames)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory '{file_directory}' not found.\")\n",
    "\n",
    "# Get the full path of a file\n",
    "def get_filepath_for_filename(filename: str) -> str:\n",
    "    base_directory = file_directory\n",
    "    return os.path.join(base_directory, filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat citations with the proper filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def reformat_citations(agent, response):\n",
    "    from semantic_kernel.contents import StreamingAnnotationContent\n",
    "\n",
    "    # Extract the annotations\n",
    "    annotations = [item for item in response.items if isinstance(item, StreamingAnnotationContent)]\n",
    "\n",
    "    # Convert the response content to a string\n",
    "    paragraph = str(response.content)\n",
    "\n",
    "    # Dictionary to store key-value pairs of text and filename\n",
    "    text_filename_pairs = {}\n",
    "\n",
    "    # Iterate over the annotations and extract the relevant information\n",
    "    for annotation in annotations:\n",
    "        file_id = annotation.file_id\n",
    "        text = annotation.quote\n",
    "        # Retrieve the filename from the file_id\n",
    "        cited_file = await agent.client.files.retrieve(file_id)\n",
    "        filename = cited_file.filename\n",
    "\n",
    "        if text not in text_filename_pairs:\n",
    "            text_filename_pairs[text] = []\n",
    "        text_filename_pairs[text].append(filename)\n",
    "\n",
    "    # Replace the citation texts with their corresponding filenames prefixed with \" Source: \"\n",
    "    for text, filenames in text_filename_pairs.items():\n",
    "        sources = \" Source: \" + \", \".join(filenames)\n",
    "        paragraph = paragraph.replace(text, sources)\n",
    "\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Agent and Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.contents import StreamingAnnotationContent\n",
    "\n",
    "# Create the client using Azure OpenAI resources and configuration\n",
    "client, model = AzureAssistantAgent.setup_resources()\n",
    "\n",
    "# Upload the files to the client\n",
    "file_ids: list[str] = []\n",
    "for path in [get_filepath_for_filename(filename) for filename in filenames]:\n",
    "    with open(path, \"rb\") as file:\n",
    "        file = await client.files.create(file=file, purpose=\"assistants\")\n",
    "        file_ids.append(file.id)\n",
    "\n",
    "vector_store = await client.vector_stores.create(\n",
    "    name=\"assistant_search\",\n",
    "    file_ids=file_ids,\n",
    ")\n",
    "\n",
    "# Get the file search tool and resources\n",
    "file_search_tools, file_search_tool_resources = AzureAssistantAgent.configure_file_search_tool(vector_store_ids=vector_store.id)\n",
    "\n",
    "# Create the assistant definition\n",
    "definition = await client.beta.assistants.create(\n",
    "    model=model,\n",
    "    instructions=\"\"\"\n",
    "        The document store contains pages from a Nasa book.\n",
    "        Always analyze the document store to provide an answer to the user's question.\n",
    "        Never rely on your knowledge of information not included in the document store.\n",
    "        Always format response using markdown.\n",
    "        \"\"\",\n",
    "    name=\"SampleAssistantAgent\",\n",
    "    tools=file_search_tools,\n",
    "    tool_resources=file_search_tool_resources,\n",
    ")\n",
    "\n",
    "# Create the agent using the client and the assistant definition\n",
    "agent = AzureAssistantAgent(\n",
    "    client=client,\n",
    "    definition=definition,\n",
    ")\n",
    "\n",
    "# Create a thread for the agent\n",
    "thread: AssistantAgentThread = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent(user_question, thread):\n",
    "   \n",
    "    async for response in agent.invoke_stream(messages=user_question, thread=thread):\n",
    "        thread = response.thread\n",
    "        annotations = [item for item in response.items if isinstance(item, StreamingAnnotationContent)]\n",
    "        #Print the Assistant response\n",
    "        if annotations is None:\n",
    "            print(f\"{response.content}\", end=\"\", flush=True)\n",
    "        else:\n",
    "            print(f\"{await reformat_citations(agent,response)}\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wide floodplains in Queensland, specifically in the Channel Country, are thought to have originated due to the extreme variation in water and sediment discharges from the rivers. This region experiences significant fluctuations in rainfall, leading to a unique hydrological pattern. Many years see no rainfall at all, causing the rivers to seemingly disappear. In contrast, years of even modest rainfall cause the main channels to carry water, often spilling into billabongs. Every few decades, tropical storms to the north can lead to immensely high water discharges that inundate the entire width of the floodplain. These extreme variations contribute to the formation and maintenance of the wide floodplains in this area Source: page-49.pdf."
     ]
    }
   ],
   "source": [
    "user_question = \"How did the wide floodplains in Queensland originate?\"\n",
    "await run_agent(user_question, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending Messages to the Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lower Amazon River forms where the coffee-colored Rio Solim√µes, rich with sediment, meets the black-tea-colored Rio Negro. This confluence occurs east of Manaus, Brazil, where the two rivers run side by side for several kilometers before their waters eventually mix due to turbulent eddies Source: page-61.pdf."
     ]
    }
   ],
   "source": [
    "user_question = \"What forms the Lower Amazon River?\"\n",
    "await run_agent(user_question, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Files, Thread, Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent is not None:\n",
    "    [await client.files.delete(file_id) for file_id in file_ids]\n",
    "    await thread.delete() if thread else None\n",
    "    await client.beta.assistants.delete(agent.id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
