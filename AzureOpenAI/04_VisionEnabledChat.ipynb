{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Images using Azure OpenAI\n",
    "\n",
    "Pre-requisites:\n",
    "1. Create Azure OpenAI resource\n",
    "2. Deploy gpt-4 and above model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Prepare the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a Path object for the image file\n",
    "image_path = Path(\"generated_image.jpg\")\n",
    "\n",
    "# Using a context manager to open the file with Path.open()\n",
    "with image_path.open(\"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the image content in the required format for the Azure OpenAI service\n",
    "content_images = [\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "    for base64_image in [base64_image]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "# Create the Vision client\n",
    "vision_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key, \n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")\n",
    "vision_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The image captures a serene residential street scene at what appears to be either early morning or late afternoon due to the soft lighting. The central focus of the image is on a cat, possibly a domestic short-haired cat with a sleek white and grey coat and distinct markings on its face, body, and legs. The cat is positioned in the middle of the street, heading towards the photographer but looking slightly to the side, giving a sense of curiosity about its surroundings.\n",
      "\n",
      "The street is lined with modern houses that feature clean architectural lines and appear to be well-maintained. These are likely suburban homes, each with a small garden space in front. The scene includes details such as green plants, a blue recycling bin, and various foliage which adds a touch of color and liveliness. On the left side, there are blossoming pink flowers, contributing to the overall appeal of the neighborhood. \n",
      "\n",
      "In the background, the image fades into a slightly blurred effect, showcasing more houses and a car parked further down the street, enhancing the depth of the photograph. The road itself is smooth and clean, and the presence of palm trees suggests a temperate or warm climate. The overall ambiance of the image is calm and quiet, depicting a peaceful residential area with a touch of nature.\n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"Describe this image in detail.\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results similar to Azure AI Vision: Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1. \"Morning patrol: this cat takes its neighborhood watch duties seriously.\"\n",
      "2. \"Caught in the act of exploring the tranquil morning streets.\"\n",
      "3. \"This kitty's got places to be and things to see!\"\n",
      "4. \"On the lookout for adventure in the quiet suburbs.\"\n",
      "5. \"Curiosity leads the way for this feline wanderer.\"\n",
      "6. \"Who's crossing the street? Just your friendly neighborhood cat.\"\n",
      "7. \"Exploring the block, one paw at a time.\"\n",
      "8. \"The street is my runway, and I'm ready to strut!\"\n",
      "9. \"A catâ€™s-eye view of suburban life.\"\n",
      "10. \"Morning strolls with whiskers and wonder.\"\n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"Provide me 10 captions for this image.\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {\n",
      "    \"description\": \"A cat walking on a suburban street with houses and plants in the background.\",\n",
      "    \"category\": \"cat\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"\"\"Analyze this image.\n",
    "    Provide response in sample JSON format.\n",
    "    {\n",
    "        \"description\": \"Describe the image in less than 50 words\",\n",
    "        \"category\": cat, dog, or mouse\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
