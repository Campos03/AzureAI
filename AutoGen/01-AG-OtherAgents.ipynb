{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Other Agents\n",
    "\n",
    "Samples of other preset agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-ext[openai]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient, OpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Web Surfer\n",
    "MultimodalWebSurfer is a multimodal agent that acts as a web surfer that can search the web and visit web pages.\n",
    "\n",
    "Note: Need to run in terminal: playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library\n",
    "%pip install \"autogen-ext[web-surfer]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "\n",
    "\n",
    "# Define an agent\n",
    "web_surfer_agent = MultimodalWebSurfer(\n",
    "    name=\"MultimodalWebSurfer\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "# Define a team\n",
    "agent_team = RoundRobinGroupChat([web_surfer_agent], max_turns=3)\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=\"Navigate to the Wikipedia page for the Eiffel Tower.\")\n",
    "await Console(stream)\n",
    "# Close the browser controlled by the agent\n",
    "await web_surfer_agent.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistant Agent\n",
    "\n",
    "An agent implementation that uses the OpenAI Assistant API to generate responses.\n",
    "\n",
    "This agent leverages the OpenAI Assistant API to create AI assistants with capabilities like:\n",
    "- Code interpretation and execution\n",
    "- File handling and search\n",
    "- Custom function calling\n",
    "- Multi-turn conversations\n",
    "\n",
    "The agent maintains a thread of conversation and can use various tools including\n",
    "- Code interpreter: For executing code and working with files\n",
    "- File search: For searching through uploaded documents\n",
    "- Custom functions: For extending capabilities with user-defined tools\n",
    "\n",
    "Key Features:\n",
    "- Supports multiple file formats including code, documents, images\n",
    "- Can handle up to 128 tools per assistant\n",
    "- Maintains conversation context in threads\n",
    "- Supports file uploads for code interpreter and search\n",
    "- Vector store integration for efficient file search\n",
    "- Automatic file parsing and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the Adventure Dining Table is $90【6:0†source】.\n",
      "The state with the most sightings is Washington, with 601 sightings.\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.agents.openai import OpenAIAssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AsyncAzureOpenAI(azure_endpoint=azure_openai_endpoint, \n",
    "                          api_version=azure_openai_api_version, \n",
    "                          api_key=azure_openai_key)\n",
    "\n",
    "#### Create a file for code interpreter ####\n",
    "file=open(\"../Data/assistant/bigfootsightings.csv\", \"rb\")\n",
    "code_interpreter_file = await client.files.create(\n",
    "  file=file,\n",
    "  purpose='assistants'\n",
    ")\n",
    "file.close()\n",
    "\n",
    "#### Create a vector store for file search ####\n",
    "vector_store = await client.beta.vector_stores.create(name=\"Hiking Products\")\n",
    "# Specify the folder containing the files\n",
    "folder_path = \"../Data/products/\"\n",
    "# Get all file paths in the folder\n",
    "file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "# Open file streams\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "# Close file streams\n",
    "for file in file_streams:\n",
    "    file.close()\n",
    "\n",
    "#### Create an assistant with code interpreter and file search ####\n",
    "assistant = OpenAIAssistantAgent(\n",
    "    name=\"DataAssistant\",\n",
    "    description=\"Answer questions about data\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will answer questions about the product files given to you. You will use Python to answer questions about a dataset\",\n",
    "    tools=[\"code_interpreter\",\"file_search\"],\n",
    "    tool_resources={\"code_interpreter\":{\"file_ids\":[code_interpreter_file.id]}, \"file_search\":{\"vector_store_ids\":[vector_store.id]}}\n",
    ")\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"What is the price of the Adventure Dining Table in the file search product set?\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"\"\"Use the code interpreter file. \n",
    "                         Which state has the most sightings? Provide the number of sightings in that state\"\"\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Clean up resources\n",
    "await assistant.delete_uploaded_files(cancellation_token)\n",
    "await assistant.delete_assistant(cancellation_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Executor Agent\n",
    "An agent that extracts and executes code snippets found in received messages and returns the output.\n",
    "\n",
    "It is typically used within a team with another agent that generates code snippets to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import CodeExecutorAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create a code executor agent that uses a Docker container to execute code.\n",
    "code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "await code_executor.start()\n",
    "code_executor_agent = CodeExecutorAgent(\"code_executor\", code_executor=code_executor)\n",
    "\n",
    "# Run the agent with a given code snippet.\n",
    "task = TextMessage(\n",
    "    content='''Here is some code\n",
    "    ```python\n",
    "print('Hello world')\n",
    "    ```\n",
    "    ''',\n",
    "    source=\"user\",\n",
    ")\n",
    "\n",
    "response = await code_executor_agent.on_messages([task], CancellationToken())\n",
    "print(response.chat_message)\n",
    "\n",
    "# Stop the code executor.\n",
    "await code_executor.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One\n",
    "https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/magentic-one.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    \"Assistant\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "team = MagenticOneGroupChat([assistant], model_client=az_model_client)\n",
    "await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfer = MultimodalWebSurfer(\n",
    "        \"WebSurfer\",\n",
    "        model_client=az_model_client,\n",
    "    )\n",
    "\n",
    "team = MagenticOneGroupChat([surfer], model_client=az_model_client)\n",
    "await Console(team.run_stream(task=\"Is there a Lakers game today?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
