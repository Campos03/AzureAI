{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Other Agents\n",
    "\n",
    "Samples of other preset agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-ext[openai]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient, OpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Web Surfer\n",
    "MultimodalWebSurfer is a multimodal agent that acts as a web surfer that can search the web and visit web pages.\n",
    "\n",
    "Note: Need to run in terminal: playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library\n",
    "%pip install \"autogen-ext[web-surfer]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date: 2025-01-11\n",
      "---------- user ----------\n",
      "Today is 2025-01-11. What is the weather like in New York?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:412: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"vision\"] is False:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:427: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"json_output\"] is False and json_output is True:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:433: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"function_calling\"] is False and len(tools) > 0:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/agents/web_surfer/_multimodal_web_surfer.py:503: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-05-13. Model mapping may be incorrect.\n",
      "  response = await self._model_client.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- MultimodalWebSurfer ----------\n",
      "I typed 'Current weather in New York' into '0 characters out of 2000'.\n",
      "\n",
      " Here is a screenshot of the webpage: [Current weather in New York - Search](https://www.bing.com/search?q=Current+weather+in+New+York&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=FFC846AAEF2246509076C0D18F6AEA7C&ghsh=0&ghacc=0&ghpl=).\n",
      " The viewport shows 27% of the webpage, and is positioned at the top of the page \n",
      "The following metadata was extracted from the webpage:\n",
      "\n",
      "{\n",
      "    \"meta_tags\": {\n",
      "        \"referrer\": \"origin-when-cross-origin\",\n",
      "        \"SystemEntropyOriginTrialToken\": \"A1L3tx5CzccqjN3lK6st/fXMwhf9EeokCPf8XCt0DVI8JPbg37BWq0zKvlqgkdm8YEUbthoGkC/xdR1+iIz4txAAAABxeyJvcmlnaW4iOiJodHRwczovL3d3dy5iaW5nLmNvbTo0NDMiLCJmZWF0dXJlIjoiTXNVc2VyQWdlbnRMYXVuY2hOYXZUeXBlIiwiZXhwaXJ5IjoxNzM5NzI0MzExLCJpc1N1YmRvbWFpbiI6dHJ1ZX0=\",\n",
      "        \"og:description\": \"Intelligent search from Bing makes it easier to quickly find what you\\u2019re looking for and rewards you.\",\n",
      "        \"og:site_name\": \"Bing\",\n",
      "        \"og:title\": \"Current weather in New York - Bing\",\n",
      "        \"og:url\": \"https://www.bing.com/search?q=Current+weather+in+New+York&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=FFC846AAEF2246509076C0D18F6AEA7C&ghsh=0&ghacc=0&ghpl=\",\n",
      "        \"fb:app_id\": \"3732605936979161\",\n",
      "        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\n",
      "        \"og:type\": \"website\",\n",
      "        \"og:image:width\": \"600\",\n",
      "        \"og:image:height\": \"315\"\n",
      "    }\n",
      "}\n",
      "\n",
      "The first 50 lines of the page text is:\n",
      "\n",
      "Skip to content\n",
      "Current weather in New York\n",
      "Deep search\n",
      "SEARCHCOPILOTNEWSIMAGESVIDEOSMAPS\n",
      "MORE\n",
      "TOOLS\n",
      "About 348,000,000 results\n",
      "New York, United States\n",
      "Updated a few minutes ago\n",
      "0\n",
      "°C\n",
      "F\n",
      "1°\n",
      "-1°\n",
      "Wind: 11 KMPH\n",
      "Humidity: 64%\n",
      "Mostly cloudySat 11, 11:15 am\n",
      "12 PM\n",
      "3 PM\n",
      "6 PM\n",
      "9 PM\n",
      "12 AM\n",
      "3 AM\n",
      "6 AM\n",
      "9 AM\n",
      "1 AM\n",
      "4 AM\n",
      "7 AM\n",
      "10 AM\n",
      "1 PM\n",
      "4 PM\n",
      "7 PM\n",
      "10 PM\n",
      "1 AM\n",
      "4 AM\n",
      "7 AM\n",
      "10 AM\n",
      "1 PM\n",
      "4 PM\n",
      "7 PM\n",
      "10 PM\n",
      "1 AM\n",
      "4 AM\n",
      "7 AM\n",
      "10 AM\n",
      "1 PM\n",
      "4 PM\n",
      "7 PM\n",
      "10 PM\n",
      "1 AM\n",
      "<image>\n",
      "[Prompt tokens: 2464, Completion tokens: 47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/asyncio/selector_events.py:875: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=71 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/codespace/.python/current/lib/python3.12/asyncio/selector_events.py:875: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=72 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/codespace/.python/current/lib/python3.12/asyncio/selector_events.py:875: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=70 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- MultimodalWebSurfer ----------\n",
      "The current weather in New York City is mostly cloudy with a temperature of 0°C (32°F). The wind is blowing at 11 km/h from the north-northwest, and the humidity level is 64%. The detailed forecast indicates that temperatures will remain around 0°C today, with minimal chances of precipitation. Looking ahead, the weather is expected to be cold with temperatures fluctuating between -1°C and 7°C over the next week.\n",
      "[Prompt tokens: 12235, Completion tokens: 134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/agents/web_surfer/_multimodal_web_surfer.py:853: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-05-13. Model mapping may be incorrect.\n",
      "  response = await self._model_client.create(messages, cancellation_token=cancellation_token)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- MultimodalWebSurfer ----------\n",
      "The current weather in New York is mostly cloudy with a temperature of 0°C (32°F), a wind speed of 11 KMPH, and a humidity level of 64%. Throughout the day, temperatures will vary slightly, with a maximum of 1°C and a minimum of -1°C. The forecast for the upcoming week shows a mix of partly cloudy and sunny days, with temperatures ranging from a high of 7°C to a low of -6°C. Historical weather data indicate typical temperature averages and extremes for January. Nearby cities like Brooklyn are also experiencing similar weather, with current temperatures around 0°C.\n",
      "[Prompt tokens: 10472, Completion tokens: 163]\n",
      "---------- Summary ----------\n",
      "Number of messages: 4\n",
      "Finish reason: Maximum number of turns 3 reached.\n",
      "Total prompt tokens: 25171\n",
      "Total completion tokens: 344\n",
      "Duration: 32.28 seconds\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "# Extract the date part\n",
    "current_date = now.date()\n",
    "print(\"Current Date:\", current_date)\n",
    "\n",
    "# Define an agent\n",
    "web_surfer_agent = MultimodalWebSurfer(\n",
    "    name=\"MultimodalWebSurfer\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "# Define a team\n",
    "agent_team = RoundRobinGroupChat([web_surfer_agent], max_turns=3)\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=f\"Today is {current_date}. What is the weather like in New York?\")\n",
    "await Console(stream)\n",
    "# Close the browser controlled by the agent\n",
    "await web_surfer_agent.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistant Agent\n",
    "\n",
    "An agent implementation that uses the OpenAI Assistant API to generate responses.\n",
    "\n",
    "This agent leverages the OpenAI Assistant API to create AI assistants with capabilities like:\n",
    "- Code interpretation and execution\n",
    "- File handling and search\n",
    "- Custom function calling\n",
    "- Multi-turn conversations\n",
    "\n",
    "The agent maintains a thread of conversation and can use various tools including\n",
    "- Code interpreter: For executing code and working with files\n",
    "- File search: For searching through uploaded documents\n",
    "- Custom functions: For extending capabilities with user-defined tools\n",
    "\n",
    "Key Features:\n",
    "- Supports multiple file formats including code, documents, images\n",
    "- Can handle up to 128 tools per assistant\n",
    "- Maintains conversation context in threads\n",
    "- Supports file uploads for code interpreter and search\n",
    "- Vector store integration for efficient file search\n",
    "- Automatic file parsing and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.agents.openai import OpenAIAssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AsyncAzureOpenAI(azure_endpoint=azure_openai_endpoint, \n",
    "                          api_version=azure_openai_api_version, \n",
    "                          api_key=azure_openai_key)\n",
    "\n",
    "\n",
    "#### Create a vector store for file search ####\n",
    "vector_store = await client.beta.vector_stores.create(name=\"Hiking Products\")\n",
    "# Specify the folder containing the files\n",
    "folder_path = \"../Data/products/\"\n",
    "# Get all file paths in the folder\n",
    "file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "# Open file streams\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "# Close file streams\n",
    "for file in file_streams:\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=20, failed=0, in_progress=0, total=20)\n",
      "vs_c23gKsnW3T3J2yk2gd6tiI8P\n"
     ]
    }
   ],
   "source": [
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the Adventure Dining Table in the file product set is $90【4:0†source】.\n"
     ]
    }
   ],
   "source": [
    "#### Create an assistant with code interpreter and file search ####\n",
    "assistant = OpenAIAssistantAgent(\n",
    "    name=\"DataAssistant\",\n",
    "    description=\"Answer questions about data\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will answer questions about the product files given to you\",\n",
    "    tools=[\"file_search\"],\n",
    "    tool_resources={\"file_search\":{\"vector_store_ids\":[vector_store.id]}}\n",
    ")\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"What is the price of the Adventure Dining Table in the file search product set?\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Clean up resources\n",
    "await assistant.delete_uploaded_files(cancellation_token)\n",
    "await assistant.delete_assistant(cancellation_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state with the most sightings is Washington, with a total of 601 sightings.\n"
     ]
    }
   ],
   "source": [
    "#### Create a file for code interpreter ####\n",
    "file=open(\"../Data/assistant/bigfootsightings.csv\", \"rb\")\n",
    "code_interpreter_file = await client.files.create(\n",
    "  file=file,\n",
    "  purpose='assistants'\n",
    ")\n",
    "file.close()\n",
    "\n",
    "#### Create an assistant with code interpreter and file search ####\n",
    "assistant = OpenAIAssistantAgent(\n",
    "    name=\"DataAssistant\",\n",
    "    description=\"Answer questions about data\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will use Python to answer questions about a dataset\",\n",
    "    tools=[\"code_interpreter\"],\n",
    "    tool_resources={\"code_interpreter\":{\"file_ids\":[code_interpreter_file.id]}}\n",
    ")\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"\"\"Use the code interpreter file. \n",
    "                         Which state has the most sightings? Provide the number of sightings in that state\"\"\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Clean up resources\n",
    "await assistant.delete_uploaded_files(cancellation_token)\n",
    "await assistant.delete_assistant(cancellation_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Executor Agent\n",
    "An agent that extracts and executes code snippets found in received messages and returns the output.\n",
    "\n",
    "It is typically used within a team with another agent that generates code snippets to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='code_executor' models_usage=None content='Hello world\\n' type='TextMessage'\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import CodeExecutorAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create a code executor agent that uses a Docker container to execute code.\n",
    "docker_code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "await docker_code_executor.start()\n",
    "\n",
    "code_executor_agent = CodeExecutorAgent(\"code_executor\", code_executor=docker_code_executor)\n",
    "\n",
    "# Run the agent with a given code snippet.\n",
    "task = TextMessage(\n",
    "    content='''Here is some code\n",
    "    ```python\n",
    "print('Hello world')\n",
    "    ```\n",
    "    ''',\n",
    "    source=\"user\",\n",
    ")\n",
    "\n",
    "response = await code_executor_agent.on_messages([task], CancellationToken())\n",
    "print(response.chat_message)\n",
    "\n",
    "# Stop the docker code executor.\n",
    "await docker_code_executor.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
