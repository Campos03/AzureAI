{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One\n",
    "https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/magentic-one.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-ext[file-surfer]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient, OpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Method to see the responses per agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_responses(response):\n",
    "    # ANSI escape code for bold text\n",
    "    bold_start = \"\\033[1m\"\n",
    "    bold_end = \"\\033[0m\"\n",
    "\n",
    "    # ANSI escape code for red text\n",
    "    red_start = \"\\033[31m\"\n",
    "    red_end = \"\\033[0m\"\n",
    "\n",
    "    print(f\"{bold_start}****************Agent Responses****************{bold_end}\")\n",
    "\n",
    "    for messages in response.messages:\n",
    "        source = messages.source\n",
    "        print(f\"{bold_start}{red_start}{source}{bold_end}{red_end}\")\n",
    "        print(messages.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One with Assistant Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    \"Assistant\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "team = MagenticOneGroupChat([assistant], model_client=az_model_client)\n",
    "response = await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n",
    "get_agent_responses(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One with a MultimodalWebSurfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "\n",
    "surfer = MultimodalWebSurfer(\n",
    "        \"WebSurfer\",\n",
    "        model_client=az_model_client,\n",
    "    )\n",
    "\n",
    "team = MagenticOneGroupChat([surfer], model_client=az_model_client)\n",
    "response = await Console(team.run_stream(task=\"Is there a Lakers game on January 5, 2025?\"))\n",
    "get_agent_responses(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One with a Code Executor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.agents import CodeExecutorAgent\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "\n",
    "# Create a code executor agent that uses a Docker container to execute code.\n",
    "code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "await code_executor.start()\n",
    "code_executor_agent = CodeExecutorAgent(\"code_executor\", code_executor=code_executor)\n",
    "\n",
    "team = MagenticOneGroupChat([code_executor_agent], model_client=az_model_client, max_turns=50)\n",
    "task = f\"\"\"\n",
    "You have been provided with a dataset named bigfootsightings.csv\n",
    "\n",
    "What are the top 10 years with the most sightings? \n",
    "Use the date column and get the year there.\n",
    "Create a column chart with the sightings in the Y-axis and years in the X-axis and save it to a PNG file and sort by descending order.\n",
    "Put the value on top of each bar\n",
    "\n",
    "\"\"\"\n",
    "response = await Console(team.run_stream(task=task))\n",
    "\n",
    "get_agent_responses(response)\n",
    "\n",
    "# Stop the code executor.\n",
    "await code_executor.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic-One with Multiple Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.agents.file_surfer._file_surfer import FileSurfer\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "\n",
    "# Create a hiking assistant agent.\n",
    "hiking_assistant = AssistantAgent(\n",
    "    \"HikingAssistant\",\n",
    "    description=\"You will create a hiking plan based on a location given to you\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You will create a hiking plan based on a location given to you\"\n",
    ")\n",
    "\n",
    "file_path = \"../Data/products/\"\n",
    "# Create a file surfer agent.\n",
    "file_surfer = FileSurfer(\n",
    "    \"FileSurfer\",\n",
    "    model_client=az_model_client\n",
    ")\n",
    "file_surfer._browser.open_path(file_path)\n",
    "\n",
    "# Create a web surfer agent.\n",
    "surfer = MultimodalWebSurfer(\n",
    "        \"WebSurfer\",\n",
    "        model_client=az_model_client,\n",
    "    )\n",
    "\n",
    "team = MagenticOneGroupChat(\n",
    "    [file_surfer, surfer, hiking_assistant],\n",
    "      model_client=az_model_client, \n",
    "      max_turns=50,)\n",
    "\n",
    "task = f\"\"\"\n",
    "You have been provided with a set of product files from file_surfer to provide product recommendations for a hiking plan.\n",
    "Web Surfer will search the internet for the weather forecast for the hiking location.\n",
    "Hiking Assistant will provide a hiking plan based on the location given to you.\n",
    "You will provide a hiking plan, a weather update and product recommendations for the hike.\n",
    "You will ask the User Proxy for approval to terminate the conversation.\n",
    "\n",
    "I want to hike in the Grand Canyon\n",
    "\n",
    "\"\"\"\n",
    "response = await Console(team.run_stream(task=task))\n",
    "get_agent_responses(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_agent_responses(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
