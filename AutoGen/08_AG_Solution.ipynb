{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "# Get the current date\n",
    "current_date = date.today()\n",
    "\n",
    "planning_agent = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=f\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        Multimodal Web Surfer: Searches for information in the internet on the weather advisory for the current date: {current_date} on the hiking location.\n",
    "        Hiking Agent: Provides a hiking plan for the hiker based on the weather advisory.\n",
    "        Product Agent: Recommends products from its file search tool.\n",
    "        Writing Agent: Writes a document combining the hiking plan, product suggestions, and weather advisory.\n",
    "        Critique Agent: Critiques the hiking plan, product agent, and writing agent and suggests improvements.\n",
    "        \n",
    "        \n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "web_surfer_agent = MultimodalWebSurfer(\n",
    "    name=\"MultimodalWebSurfer\",\n",
    "    model_client=az_model_client,\n",
    "    description=\"A web surfer agent that searches for information on the internet.\",\n",
    ")\n",
    "\n",
    "hiking_agent = AssistantAgent(\n",
    "    \"HikingAgent\",\n",
    "    description=\"A Hiking agent. Writes a hiking plan based on the weather advisory.\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a Hiking agent.\n",
    "    You will create a hiking plan based on the weather advisory.\n",
    "    After writing the hiking plan, you will pass it to the Critique agent for review.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "critique_agent = AssistantAgent(\n",
    "    \"CritiqueAgent\",\n",
    "    description=\"A critique agent. Critiques the Hiking plan, product suggestions, and writing agent.\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a Critique agent.\n",
    "    You need to ensure that the hiking plan is well thought out and provides constructive feedback.\n",
    "    You need to ensure the multi-modal web surfer has provided the correct information on the weather\n",
    "    You need to ensure that the product agent provides products from file search tool such as the CozyNights Sleeping Bag, BaseCamp Folding Table, and many more.\n",
    "    You need to ensure that the writing agent has combined the hiking plan, the product suggestions, and weather advisory into a single document.\n",
    "    You need to ensure feedback from user is incorporated and ask agents to make necessary changes.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Define a tool to write the content to a file\n",
    "async def write_to_file(content: str) -> str:\n",
    "    # Write the content to a file\n",
    "    with open(\"output/output.txt\", \"w\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "writing_agent = AssistantAgent(\n",
    "    \"WritingAgent\",\n",
    "    description=\"A Writing agent that combines the hiking plan, product suggestions, and weather advisory into a single document.\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[write_to_file],\n",
    "    system_message=\"\"\"\n",
    "    You are a writing agent.\n",
    "    You will combine the hiking plan, the product suggestions, and weather advisory into a single document.\n",
    "    You will write the final output to a file.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Create the user proxy agent.\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)  # Use input() to get user input from console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.agents.openai import OpenAIAssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AsyncAzureOpenAI(azure_endpoint=azure_openai_endpoint, \n",
    "                          api_version=azure_openai_api_version, \n",
    "                          api_key=azure_openai_key)\n",
    "\n",
    "#### Create a vector store for file search ####\n",
    "vector_store = await client.beta.vector_stores.create(name=\"Hiking Products\")\n",
    "# Specify the folder containing the files\n",
    "folder_path = \"../Data/products/\"\n",
    "# Get all file paths in the folder\n",
    "file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "# Open file streams\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "# Close file streams\n",
    "for file in file_streams:\n",
    "    file.close()\n",
    "\n",
    "#### Create an assistant with file search ####\n",
    "product_agent = OpenAIAssistantAgent(\n",
    "    name=\"ProductAgent\",\n",
    "    description=\"Suggestions for products\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will provide possible products for the hiker based on the file search tool such as the TrailMaster X4 Tent, CozyNights Sleeping Bag, and more.\",\n",
    "    tools=[\"file_search\"],\n",
    "    tool_resources={\"file_search\":{\"vector_store_ids\":[vector_store.id]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the product agent\n",
    "user_input = TextMessage(source=\"user\", content=\"What is the price of the TrailMaster X4 Tent?\")\n",
    "response = await product_agent.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the team\n",
    "Let’s create the team with two termination conditions: \n",
    "- TextMentionTermination to end the conversation when the User Proxy sends “APPROVE”\n",
    "- MaxMessageTermination to limit the conversation to avoid infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mention_termination = TextMentionTermination(\"APPROVE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=50)\n",
    "termination = text_mention_termination | max_messages_termination\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    [planning_agent, web_surfer_agent, hiking_agent, product_agent, writing_agent, critique_agent, user_proxy],\n",
    "    model_client=az_model_client,\n",
    "    termination_condition=termination,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Task and Run the Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"I want to hike in the Grand Canyon, Arizona, USA.\"\n",
    "# Use asyncio.run(...) if you are running this in a script.\n",
    "response = await Console(team.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing whole response per agent source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape code for bold text\n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0m\"\n",
    "\n",
    "# ANSI escape code for red text\n",
    "red_start = \"\\033[31m\"\n",
    "red_end = \"\\033[0m\"\n",
    "\n",
    "for messages in response.messages:\n",
    "    source = messages.source\n",
    "    print(f\"{bold_start}{red_start}{source}{bold_end}{red_end}\")\n",
    "    print(messages.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the resources\n",
    "Clean up the OpenAI Assistant Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "await product_agent.delete_uploaded_files(cancellation_token)\n",
    "await product_agent.delete_assistant(cancellation_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
