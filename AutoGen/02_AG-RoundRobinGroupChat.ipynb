{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen RoundRobinGroupChat\n",
    "A team is a group of agents that work together to achieve a common goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Team\n",
    "\n",
    "RoundRobinGroupChat is a team configuration where all agents share the same context and take turns responding in a round-robin fashion. Each agent, during its turn, broadcasts its response to all other agents, ensuring that the entire team maintains a consistent context.\n",
    "\n",
    "We create a team with two AssistantAgent and a TextMentionTermination condition that stops the team when a specific word is detected in the agent’s response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.conditions import ExternalTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that stops the task if the critic approves.\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create a team with the primary and critic agents.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Team\n",
    "Call the run() method to start the team with a task.\n",
    "\n",
    "The termination condition was met when the word “APPROVE” is detected in the agent’s response. When the team stops, it returns a TaskResult object with all the messages produced by the agents in the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:343: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-05-13. Model mapping may be incorrect.\n",
      "  result = await self._model_client.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=123), content=\"Leaves of amber, gold, and red,\\nFluttering whispers overhead,\\nCrisp air paints the twilight skies,\\nAs autumn’s gentle breath complies.\\n\\nPumpkin patches, harvest moon,\\nRustling woods in quiet tune,\\nSweaters, scarves, and boots appear,\\nHeralding this time of year.\\n\\nBonfires warm with crackling glow,\\nStories shared as embers grow,\\nNature’s palette, rich and bright,\\nGuides us to the sleepy night.\\n\\nIn fall’s embrace, we find retreat,\\nA soothing rhythm, bittersweet,\\nFor as the fleeting moments pass,\\nWe cherish autumn's gentle grasp.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=168, completion_tokens=190), content='Your poem beautifully captures the essence of the fall season with vivid imagery and a soothing rhythm. However, there are a few minor suggestions to enhance it further:\\n\\n1. **Line 1**: Consider substituting \"of\" with another word for a smoother flow. For example, \"Leaves in amber, gold, and red,\"\\n2. **Line 4**: \"Autumn’s gentle breath complies\" could be rephrased for clarity. Perhaps, \"Autumn\\'s gentle breath aligns.\"\\n3. **Line 8**: \"Heralding this time of year\" feels slightly generic. Maybe something more descriptive like \"Welcoming the autumn cheer.\"\\n4. **Line 12**: Could use a bit more imagery. Instead of \"Stories shared as embers grow,\" maybe \"Tales unfold as embers glow.\"\\n\\nThese suggestions aim to enhance the imagery and lyrical quality of your poem. Overall, it\\'s a lovely piece!', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=351, completion_tokens=141), content=\"Thank you for your thoughtful feedback. Here’s a revised version of the poem incorporating your suggestions:\\n\\nLeaves in amber, gold, and red,\\nFluttering whispers overhead,\\nCrisp air paints the twilight skies,\\nAs autumn’s gentle breath aligns.\\n\\nPumpkin patches, harvest moon,\\nRustling woods in quiet tune,\\nSweaters, scarves, and boots appear,\\nWelcoming the autumn cheer.\\n\\nBonfires warm with crackling glow,\\nTales unfold as embers glow,\\nNature’s palette, rich and bright,\\nGuides us to the sleepy night.\\n\\nIn fall’s embrace, we find retreat,\\nA soothing rhythm, bittersweet,\\nFor as the fleeting moments pass,\\nWe cherish autumn's gentle grasp.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=509, completion_tokens=81), content='Your revised poem reads beautifully and the adjustments you made enhance its lyrical quality and imagery. \"Welcoming the autumn cheer\" and \"Tales unfold as embers glow\" create a more vivid and engaging picture. The slight tweak in the first line also improves the flow. \\n\\nGreat job on the revisions! The poem now has a more harmonious and rich portrayal of the fall season. \\n\\nAPPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")\n"
     ]
    }
   ],
   "source": [
    "# When running inside a script, use a async main function and call it from `asyncio.run(...)`.\n",
    "result = await team.run(task=\"Write a short poem about the fall season.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing a Team\n",
    "Similar to the agent’s on_messages_stream() method, you can stream the team’s messages while it is running by calling the run_stream() method. This method returns a generator that yields messages produced by the agents in the team as they are generated, with the final item being the TaskResult object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='user' models_usage=None content='Write a short poem about the fall season.' type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=28, completion_tokens=96) content=\"Golden leaves in crisp air twirl,\\nAutumn’s dance, a whispered whirl.\\nPumpkin patches, orchard’s yield,\\nHarvest bounty, nature’s shield.\\n\\nMoments soft in amber light,\\nSweater wrapped in cozy night.\\nBonfires blaze with stories told,\\nWarmth of hearts as nights grow cold.\\n\\nGeese in flight, a southward stream,\\nMisty mornings, nature's dream.\\nFall's embrace, a fleeting sigh,\\nBeauty’s breath as trees comply.\" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=141, completion_tokens=152) content='What a beautifully crafted poem capturing the essence of fall!\\n\\n1. The imagery evokes the vivid colors and atmosphere of the season splendidly.\\n2. The rhythm and rhyme create a soothing flow that enhances the reading experience.\\n3. The progression from describing the environment to the emotions and activities associated with fall gives a well-rounded snapshot of the season.\\n\\nHere are a few minor suggestions for refinement:\\n\\n1. **Line 3**: Maybe consider \"Pumpkin patches and orchard’s yield,\" for smoother reading.\\n2. **Line 8**: \"Warmth of hearts as the nights grow cold.\" Adding \"the\" can improve the rhythm slightly.\\n\\nOverall, excellent work! Please make these tiny adjustments if they resonate with you, and it\\'s perfect to go.' type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=286, completion_tokens=132) content=\"Thank you for the kind and insightful feedback! Here is the revised version of the poem with your suggestions incorporated:\\n\\nGolden leaves in crisp air twirl,\\nAutumn’s dance, a whispered whirl.\\nPumpkin patches and orchard’s yield,\\nHarvest bounty, nature’s shield.\\n\\nMoments soft in amber light,\\nSweater wrapped in cozy night.\\nBonfires blaze with stories told,\\nWarmth of hearts as the nights grow cold.\\n\\nGeese in flight, a southward stream,\\nMisty mornings, nature's dream.\\nFall's embrace, a fleeting sigh,\\nBeauty’s breath as trees comply.\\n\\nI hope this version resonates even more with the essence of fall!\" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=435, completion_tokens=4) content='APPROVE' type='TextMessage'\n",
      "Stop Reason: Text 'APPROVE' mentioned\n"
     ]
    }
   ],
   "source": [
    "# When running inside a script, use a async main function and call it from `asyncio.run(...)`.\n",
    "await team.reset()  # Reset the team for a new task.\n",
    "async for message in team.run_stream(task=\"Write a short poem about the fall season.\"):\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Console()\n",
    "The Console() method provides a convenient way to print messages to the console with proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- primary ----------\n",
      "Golden leaves in crisp air dance,\n",
      "Whispers of an autumn trance.\n",
      "Pumpkin scents and apple treats,\n",
      "Crunching paths beneath our feet.\n",
      "\n",
      "Sweaters woven, fires warm,\n",
      "Nature dons her twilight form.\n",
      "Crimson, amber, woodland hue,\n",
      "Painting skies a softer blue.\n",
      "\n",
      "Mornings draped in misty veils,\n",
      "Evening's hush as daylight pales.\n",
      "Time of harvest, heart's delight,\n",
      "Fall's embrace, the world's goodnight.\n",
      "[Prompt tokens: 28, Completion tokens: 92]\n",
      "---------- critic ----------\n",
      "Your poem beautifully captures the essence of fall! Your imagery of golden leaves, pumpkin scents, and crisp air evokes the sensory experience of the season. The flow and rhythm of your verses are pleasant and engaging. The vivid descriptions of autumn's transition and embrace are well-executed.\n",
      "\n",
      "However, if you would like to enhance your poem even further, consider adding a personal touch or a unique perspective, such as how fall personally affects you or those around you. This could create an even deeper emotional connection with the reader. Overall, excellent work!\n",
      "\n",
      "If you make any amendments or additions, let me know—I would be happy to review them!\n",
      "[Prompt tokens: 137, Completion tokens: 128]\n",
      "---------- primary ----------\n",
      "Thank you for your thoughtful critique! Here’s a revised version of the poem with a personal touch:\n",
      "\n",
      "Golden leaves in crisp air dance,\n",
      "Whispers of an autumn trance.\n",
      "Pumpkin scents and apple treats,\n",
      "Crunching paths beneath our feet.\n",
      "\n",
      "Sweaters woven, fires warm,\n",
      "Nature dons her twilight form.\n",
      "Crimson, amber, woodland hue,\n",
      "Painting skies a softer blue.\n",
      "\n",
      "Morning drives through misty veils,\n",
      "Children's laughter as daylight pales.\n",
      "Grandma's kitchen, pies in store,\n",
      "Harvest moons we all adore.\n",
      "\n",
      "Memories in each cool breeze,\n",
      "Moments etched in falling leaves.\n",
      "Fall's embrace, we come alive,\n",
      "In its magic, we all thrive.\n",
      "[Prompt tokens: 258, Completion tokens: 136]\n",
      "---------- critic ----------\n",
      "This revised version of your poem adds a warm and personal touch that deepens the connection with the reader. The imagery of morning drives, children's laughter, and Grandma's kitchen brings an intimate, cozy feel to the poem. The added personal elements enhance the overall emotional impact.\n",
      "\n",
      "Great job incorporating those suggestions while maintaining the beautiful flow and vivid descriptions from the original poem. The changes create a lovely balance between universal autumn experiences and personal memories. Well done!\n",
      "\n",
      "APPROVE.\n",
      "[Prompt tokens: 411, Completion tokens: 94]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Text 'APPROVE' mentioned\n",
      "Total prompt tokens: 834\n",
      "Total completion tokens: 450\n",
      "Duration: 6.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=92), content=\"Golden leaves in crisp air dance,\\nWhispers of an autumn trance.\\nPumpkin scents and apple treats,\\nCrunching paths beneath our feet.\\n\\nSweaters woven, fires warm,\\nNature dons her twilight form.\\nCrimson, amber, woodland hue,\\nPainting skies a softer blue.\\n\\nMornings draped in misty veils,\\nEvening's hush as daylight pales.\\nTime of harvest, heart's delight,\\nFall's embrace, the world's goodnight.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=137, completion_tokens=128), content=\"Your poem beautifully captures the essence of fall! Your imagery of golden leaves, pumpkin scents, and crisp air evokes the sensory experience of the season. The flow and rhythm of your verses are pleasant and engaging. The vivid descriptions of autumn's transition and embrace are well-executed.\\n\\nHowever, if you would like to enhance your poem even further, consider adding a personal touch or a unique perspective, such as how fall personally affects you or those around you. This could create an even deeper emotional connection with the reader. Overall, excellent work!\\n\\nIf you make any amendments or additions, let me know—I would be happy to review them!\", type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=258, completion_tokens=136), content=\"Thank you for your thoughtful critique! Here’s a revised version of the poem with a personal touch:\\n\\nGolden leaves in crisp air dance,\\nWhispers of an autumn trance.\\nPumpkin scents and apple treats,\\nCrunching paths beneath our feet.\\n\\nSweaters woven, fires warm,\\nNature dons her twilight form.\\nCrimson, amber, woodland hue,\\nPainting skies a softer blue.\\n\\nMorning drives through misty veils,\\nChildren's laughter as daylight pales.\\nGrandma's kitchen, pies in store,\\nHarvest moons we all adore.\\n\\nMemories in each cool breeze,\\nMoments etched in falling leaves.\\nFall's embrace, we come alive,\\nIn its magic, we all thrive.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=411, completion_tokens=94), content=\"This revised version of your poem adds a warm and personal touch that deepens the connection with the reader. The imagery of morning drives, children's laughter, and Grandma's kitchen brings an intimate, cozy feel to the poem. The added personal elements enhance the overall emotional impact.\\n\\nGreat job incorporating those suggestions while maintaining the beautiful flow and vivid descriptions from the original poem. The changes create a lovely balance between universal autumn experiences and personal memories. Well done!\\n\\nAPPROVE.\", type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await team.reset()  # Reset the team for a new task.\n",
    "await Console(team.run_stream(task=\"Write a short poem about the fall season.\"))  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team has a State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What was the last message?\n",
      "---------- primary ----------\n",
      "The last message was a positive critique and approval of your revised version of the fall season poem. It highlighted how your additions of morning drives, children's laughter, and Grandma's kitchen added a personal and cozy touch to the poem, deepening the emotional connection for the reader. The critique also praised the balance between universal autumn experiences and personal memories, maintaining the beautiful flow and vivid descriptions from the original poem. The overall feedback was very approving and complimentary of your work.\n",
      "[Prompt tokens: 509, Completion tokens: 93]\n",
      "---------- critic ----------\n",
      "APPROVE\n",
      "[Prompt tokens: 619, Completion tokens: 4]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: Text 'APPROVE' mentioned\n",
      "Total prompt tokens: 1128\n",
      "Total completion tokens: 97\n",
      "Duration: 1.54 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What was the last message?', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=509, completion_tokens=93), content=\"The last message was a positive critique and approval of your revised version of the fall season poem. It highlighted how your additions of morning drives, children's laughter, and Grandma's kitchen added a personal and cozy touch to the poem, deepening the emotional connection for the reader. The critique also praised the balance between universal autumn experiences and personal memories, maintaining the beautiful flow and vivid descriptions from the original poem. The overall feedback was very approving and complimentary of your work.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=619, completion_tokens=4), content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task=\"What was the last message?\"))  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetting a Team\n",
    "You can reset the team by calling the reset() method. This method will clear the team’s state, including all agents. It will call the each agent’s on_reset() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset()  # Reset the team for the next run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping a Team\n",
    "You can also stop the team from outside by using the ExternalTermination.\n",
    "\n",
    "Calling set() on ExternalTermination will stop the team when the current agent’s turn is over. \n",
    "\n",
    "Thus, the team may not stop immediately. This allows the current agent to finish its turn and broadcast the final message to the team before the team stops, keeping the team’s state consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- primary ----------\n",
      "Leaves descend in a golden dance,\n",
      "Whispers of autumn's sweet romance.\n",
      "A tapestry of crimson and gold,\n",
      "Stories of summer softly told.\n",
      "\n",
      "Crisp air carries distant chimes,\n",
      "Harvest moons and apple climbs.\n",
      "Warmth retreats, yet hearts ignite,\n",
      "In the embrace of fall's delight.\n",
      "\n",
      "Pumpkin patches, fireside tales,\n",
      "Rustling woods and winding trails.\n",
      "Nature's quilt in vibrant hue,\n",
      "A fleeting time, yet born anew.\n",
      "\n",
      "Through swirling winds and fading light,\n",
      "Autumn weaves the day to night.\n",
      "A gentle pause before the snow,\n",
      "In fall's embrace, the world aglow.\n",
      "[Prompt tokens: 28, Completion tokens: 123]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: External termination requested\n",
      "Total prompt tokens: 28\n",
      "Total completion tokens: 123\n",
      "Duration: 1.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=123), content=\"Leaves descend in a golden dance,\\nWhispers of autumn's sweet romance.\\nA tapestry of crimson and gold,\\nStories of summer softly told.\\n\\nCrisp air carries distant chimes,\\nHarvest moons and apple climbs.\\nWarmth retreats, yet hearts ignite,\\nIn the embrace of fall's delight.\\n\\nPumpkin patches, fireside tales,\\nRustling woods and winding trails.\\nNature's quilt in vibrant hue,\\nA fleeting time, yet born anew.\\n\\nThrough swirling winds and fading light,\\nAutumn weaves the day to night.\\nA gentle pause before the snow,\\nIn fall's embrace, the world aglow.\", type='TextMessage')], stop_reason='External termination requested')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new team with an external termination condition.\n",
    "external_termination = ExternalTermination()\n",
    "team = RoundRobinGroupChat(\n",
    "    [primary_agent, critic_agent],\n",
    "    termination_condition=external_termination | text_termination,  # Use the bitwise OR operator to combine conditions.\n",
    ")\n",
    "\n",
    "# Run the team in a background task.\n",
    "run = asyncio.create_task(Console(team.run_stream(task=\"Write a short poem about the fall season.\")))\n",
    "\n",
    "# Wait for some time.\n",
    "await asyncio.sleep(0.1)\n",
    "\n",
    "# Stop the team.\n",
    "external_termination.set()\n",
    "\n",
    "# Wait for the team to finish.\n",
    "await run # Primary agent is still allowed to complete its task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming a Team\n",
    "Teams are stateful and maintains the conversation history and context after each run, unless you reset the team.\n",
    "\n",
    "You can resume a team to continue from where it left off by calling the run() or run_stream() method again without a new task. RoundRobinGroupChat will continue from the next agent in the round-robin order.\n",
    "\n",
    "In this example, critic agent continued where primary agent left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- critic ----------\n",
      "Your poem beautifully captures the essence of the fall season. Here are some areas where you might enhance the imagery and rhythm:\n",
      "\n",
      "1. The first stanza sets a lovely scene but might benefit from a more unique phrasing. Consider reworking the second line for even more impact.\n",
      "\n",
      "2. The second stanza is quite charming but the last line could be revised to enhance the meter. Perhaps something like: \"In fall's gentle, glowing light.\"\n",
      "\n",
      "3. The third stanza starts strong with imagery, but the last two lines feel a bit rushed. Maybe add more descriptive words or slow the pace slightly.\n",
      "\n",
      "4. The final stanza has a serene mood, but consider a stronger closing image to leave a lasting impression.\n",
      "\n",
      "Overall, these suggestions are merely to fine-tune an already beautiful piece. You've captured the warmth and beauty of the fall season admirably. \n",
      "\n",
      "Please revise and I am sure it will be fantastic.\n",
      "[Prompt tokens: 168, Completion tokens: 181]\n",
      "---------- primary ----------\n",
      "Leaves descend in a golden dance,\n",
      "Autumn whispers a chance romance.\n",
      "Tapestries of crimson bold,\n",
      "Tales of summer, softly told.\n",
      "\n",
      "Crisp air carries distant chimes,\n",
      "Harvest moons and lofty climbs.\n",
      "Warmth retreats, our souls take flight,\n",
      "In fall’s gentle, glowing light.\n",
      "\n",
      "Pumpkin patches, fireside tales,\n",
      "Rustling woods and winding trails.\n",
      "Nature’s quilt in vibrant hue,\n",
      "Moments cherished, pure and true.\n",
      "\n",
      "Through swirling winds, the day turns night,\n",
      "Autumn weaves with tender might.\n",
      "A gentle pause before the snow,\n",
      "In fall's embrace, the heart aglow.\n",
      "[Prompt tokens: 342, Completion tokens: 126]\n",
      "---------- critic ----------\n",
      "Your revised poem has improved in imagery and rhythm. Here are a few final suggestions:\n",
      "\n",
      "1. In the first stanza, \"Autumn whispers a chance romance\" might flow better as \"Autumn whispers of chance romance.\"\n",
      "\n",
      "2. The second stanza's fourth line is now perfect! \n",
      "\n",
      "3. The third stanza is much improved with the new phrasing, making it more vivid and engaging.\n",
      "\n",
      "4. The final stanza has a beautiful closing image. Well done!\n",
      "\n",
      "Overall, these minor adjustments will further enhance the poem's fluidity. Fantastic work on the revisions! With these tweaks, the poem will shine even brighter.\n",
      "\n",
      "APPROVE\n",
      "[Prompt tokens: 485, Completion tokens: 127]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: Text 'APPROVE' mentioned\n",
      "Total prompt tokens: 995\n",
      "Total completion tokens: 434\n",
      "Duration: 5.39 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=168, completion_tokens=181), content='Your poem beautifully captures the essence of the fall season. Here are some areas where you might enhance the imagery and rhythm:\\n\\n1. The first stanza sets a lovely scene but might benefit from a more unique phrasing. Consider reworking the second line for even more impact.\\n\\n2. The second stanza is quite charming but the last line could be revised to enhance the meter. Perhaps something like: \"In fall\\'s gentle, glowing light.\"\\n\\n3. The third stanza starts strong with imagery, but the last two lines feel a bit rushed. Maybe add more descriptive words or slow the pace slightly.\\n\\n4. The final stanza has a serene mood, but consider a stronger closing image to leave a lasting impression.\\n\\nOverall, these suggestions are merely to fine-tune an already beautiful piece. You\\'ve captured the warmth and beauty of the fall season admirably. \\n\\nPlease revise and I am sure it will be fantastic.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=342, completion_tokens=126), content=\"Leaves descend in a golden dance,\\nAutumn whispers a chance romance.\\nTapestries of crimson bold,\\nTales of summer, softly told.\\n\\nCrisp air carries distant chimes,\\nHarvest moons and lofty climbs.\\nWarmth retreats, our souls take flight,\\nIn fall’s gentle, glowing light.\\n\\nPumpkin patches, fireside tales,\\nRustling woods and winding trails.\\nNature’s quilt in vibrant hue,\\nMoments cherished, pure and true.\\n\\nThrough swirling winds, the day turns night,\\nAutumn weaves with tender might.\\nA gentle pause before the snow,\\nIn fall's embrace, the heart aglow.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=485, completion_tokens=127), content='Your revised poem has improved in imagery and rhythm. Here are a few final suggestions:\\n\\n1. In the first stanza, \"Autumn whispers a chance romance\" might flow better as \"Autumn whispers of chance romance.\"\\n\\n2. The second stanza\\'s fourth line is now perfect! \\n\\n3. The third stanza is much improved with the new phrasing, making it more vivid and engaging.\\n\\n4. The final stanza has a beautiful closing image. Well done!\\n\\nOverall, these minor adjustments will further enhance the poem\\'s fluidity. Fantastic work on the revisions! With these tweaks, the poem will shine even brighter.\\n\\nAPPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())  # Resume the team to continue the last task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aborting a Team\n",
    "You can abort a call to run() or run_stream() during execution by setting a CancellationToken passed to the cancellation_token parameter.\n",
    "\n",
    "Different from stopping a team, aborting a team will immediately stop the team and raise a CancelledError exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task was cancelled.\n"
     ]
    }
   ],
   "source": [
    "# Create a cancellation token.\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Use another coroutine to run the team.\n",
    "run = asyncio.create_task(\n",
    "    team.run(\n",
    "        task=\"Translate the poem to Spanish.\",\n",
    "        cancellation_token=cancellation_token,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cancel the run.\n",
    "cancellation_token.cancel()\n",
    "\n",
    "try:\n",
    "    result = await run  # This will raise a CancelledError.\n",
    "except asyncio.CancelledError:\n",
    "    print(\"Task was cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Built-In Termination Conditions:\n",
    "- MaxMessageTermination: Stops after a specified number of messages have been produced, including both agent and task messages.\n",
    "- TextMentionTermination: Stops when specific text or string is mentioned in a message (e.g., “TERMINATE”).\n",
    "- ExternalTermination: Enables programmatic control of termination from outside the run. This is useful for UI integration (e.g., “Stop” buttons in chat interfaces).\n",
    "- TokenUsageTermination: Stops when a certain number of prompt or completion tokens are used. This requires the agents to report token usage in their messages.\n",
    "- TimeoutTermination: Stops after a specified duration in seconds.\n",
    "- SourceMatchTermination: Stops after a specific agent responds.\n",
    "- HandoffTermination: Stops when a handoff to a specific target is requested. Handoff messages can be used to build patterns such as Swarm. This is useful when you want to pause the run and allow application or user to provide input when an agent hands off to them.\n",
    "- StopMessageTermination: Stops when a StopMessage is produced by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "Sure! How about the number 7?\n",
      "[Prompt tokens: 28, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "Let's go with the number 3.\n",
      "[Prompt tokens: 42, Completion tokens: 9]\n",
      "---------- third ----------\n",
      "I'll choose the number 8 for you.\n",
      "[Prompt tokens: 56, Completion tokens: 10]\n",
      "---------- first ----------\n",
      "All right, you got the number 8!\n",
      "[Prompt tokens: 71, Completion tokens: 11]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Maximum number of messages 5 reached, current message count: 5\n",
      "Total prompt tokens: 197\n",
      "Total completion tokens: 40\n",
      "Duration: 1.68 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=10), content='Sure! How about the number 7?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=42, completion_tokens=9), content=\"Let's go with the number 3.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=56, completion_tokens=10), content=\"I'll choose the number 8 for you.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=71, completion_tokens=11), content='All right, you got the number 8!', type='TextMessage')], stop_reason='Maximum number of messages 5 reached, current message count: 5')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination, ExternalTermination, TokenUsageTermination, TimeoutTermination, SourceMatchTermination, HandoffTermination, StopMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Create the first agent.\n",
    "first_agent = AssistantAgent(\n",
    "    \"first\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You will give a random number between 1 and 10.\",\n",
    ")\n",
    "\n",
    "# Create the second agent.\n",
    "second_agent = AssistantAgent(\n",
    "    \"second\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You will give a random number between 1 and 10.\",\n",
    ")\n",
    "\n",
    "# Create the second agent.\n",
    "third_agent = AssistantAgent(\n",
    "    \"third\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You will give a random number between 1 and 10.\",\n",
    ")\n",
    "\n",
    "# MaxMessageTermination\n",
    "termination = MaxMessageTermination(5) # terminate after 5 messages\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "\n",
    "await Console(team.run_stream(task=\"Give a number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "How about the number 5?\n",
      "[Prompt tokens: 94, Completion tokens: 8]\n",
      "---------- second ----------\n",
      "Let's go with the number 8.\n",
      "[Prompt tokens: 76, Completion tokens: 9]\n",
      "---------- third ----------\n",
      "I'll choose the number 2 for you.\n",
      "[Prompt tokens: 105, Completion tokens: 10]\n",
      "---------- first ----------\n",
      "Alright, the number is 2!\n",
      "[Prompt tokens: 135, Completion tokens: 9]\n",
      "---------- second ----------\n",
      "Alright, I'll give you the number 6.\n",
      "[Prompt tokens: 118, Completion tokens: 11]\n",
      "---------- third ----------\n",
      "How about the number 4?\n",
      "[Prompt tokens: 149, Completion tokens: 8]\n",
      "---------- Summary ----------\n",
      "Number of messages: 7\n",
      "Finish reason: Text '4' mentioned\n",
      "Total prompt tokens: 677\n",
      "Total completion tokens: 55\n",
      "Duration: 2.50 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=94, completion_tokens=8), content='How about the number 5?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=76, completion_tokens=9), content=\"Let's go with the number 8.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=105, completion_tokens=10), content=\"I'll choose the number 2 for you.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=135, completion_tokens=9), content='Alright, the number is 2!', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=118, completion_tokens=11), content=\"Alright, I'll give you the number 6.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=149, completion_tokens=8), content='How about the number 4?', type='TextMessage')], stop_reason=\"Text '4' mentioned\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextMentionTermination\n",
    "termination = TextMentionTermination(\"4\") # Terminate when the message contains \"4\".\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "await Console(team.run_stream(task=\"Give a number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "Sure! How about the number 4?\n",
      "[Prompt tokens: 156, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "I suggest the number 9.\n",
      "[Prompt tokens: 156, Completion tokens: 8]\n",
      "---------- third ----------\n",
      "Let's go with the number 1.\n",
      "[Prompt tokens: 197, Completion tokens: 9]\n",
      "---------- first ----------\n",
      "Alright, you got the number 1!\n",
      "[Prompt tokens: 197, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "I'm giving you the number 10.\n",
      "[Prompt tokens: 197, Completion tokens: 9]\n",
      "---------- third ----------\n",
      "I'll go with the number 7.\n",
      "[Prompt tokens: 239, Completion tokens: 9]\n",
      "---------- first ----------\n",
      "Great choice! The number is 7.\n",
      "[Prompt tokens: 239, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "Let's go with the number 5.\n",
      "[Prompt tokens: 239, Completion tokens: 9]\n",
      "---------- Summary ----------\n",
      "Number of messages: 9\n",
      "Finish reason: External termination requested\n",
      "Total prompt tokens: 1620\n",
      "Total completion tokens: 74\n",
      "Duration: 3.33 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=156, completion_tokens=10), content='Sure! How about the number 4?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=156, completion_tokens=8), content='I suggest the number 9.', type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=197, completion_tokens=9), content=\"Let's go with the number 1.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=197, completion_tokens=10), content='Alright, you got the number 1!', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=197, completion_tokens=9), content=\"I'm giving you the number 10.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=239, completion_tokens=9), content=\"I'll go with the number 7.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=239, completion_tokens=10), content='Great choice! The number is 7.', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=239, completion_tokens=9), content=\"Let's go with the number 5.\", type='TextMessage')], stop_reason='External termination requested')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "#ExternalTermination\n",
    "termination = ExternalTermination() # Create an external termination condition.\n",
    "\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "\n",
    "# Run the team in a background task.\n",
    "run = asyncio.create_task(Console(team.run_stream(task=\"Give a number\")))\n",
    "\n",
    "# Wait for some time.\n",
    "await asyncio.sleep(3)\n",
    "\n",
    "# Stop the team.\n",
    "termination.set()\n",
    "\n",
    "# Wait for the team to finish.\n",
    "await run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "Sure! How about the number 6?\n",
      "[Prompt tokens: 261, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "How about the number 3?\n",
      "[Prompt tokens: 275, Completion tokens: 8]\n",
      "---------- third ----------\n",
      "Let's go with the number 5.\n",
      "[Prompt tokens: 288, Completion tokens: 9]\n",
      "---------- first ----------\n",
      "Alright, the number is 5!\n",
      "[Prompt tokens: 302, Completion tokens: 9]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Token usage limit reached, total token count: 1162, prompt token count: 1126, completion token count: 36.\n",
      "Total prompt tokens: 1126\n",
      "Total completion tokens: 36\n",
      "Duration: 1.57 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=261, completion_tokens=10), content='Sure! How about the number 6?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=275, completion_tokens=8), content='How about the number 3?', type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=288, completion_tokens=9), content=\"Let's go with the number 5.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=302, completion_tokens=9), content='Alright, the number is 5!', type='TextMessage')], stop_reason='Token usage limit reached, total token count: 1162, prompt token count: 1126, completion token count: 36.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TokenUsageTermination\n",
    "termination = TokenUsageTermination(1000) # terminate when token usage is met.\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "await Console(team.run_stream(task=\"Give a number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "Sure! How about the number 4?\n",
      "[Prompt tokens: 323, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "Let's go with the number 9.\n",
      "[Prompt tokens: 310, Completion tokens: 9]\n",
      "---------- third ----------\n",
      "How about the number 2?\n",
      "[Prompt tokens: 338, Completion tokens: 8]\n",
      "---------- first ----------\n",
      "Alright, the number is 2!\n",
      "[Prompt tokens: 364, Completion tokens: 9]\n",
      "---------- second ----------\n",
      "Alright, I'll go with the number 8.\n",
      "[Prompt tokens: 350, Completion tokens: 11]\n",
      "---------- third ----------\n",
      "How about the number 7?\n",
      "[Prompt tokens: 380, Completion tokens: 8]\n",
      "---------- first ----------\n",
      "Sure, let's go with the number 7!\n",
      "[Prompt tokens: 406, Completion tokens: 11]\n",
      "---------- second ----------\n",
      "Sure, let's go with the number 7!\n",
      "[Prompt tokens: 394, Completion tokens: 11]\n",
      "---------- third ----------\n",
      "How about the number 3?\n",
      "[Prompt tokens: 424, Completion tokens: 8]\n",
      "---------- first ----------\n",
      "Great choice! The number is 3.\n",
      "[Prompt tokens: 450, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "Alright, let's go with the number 3.\n",
      "[Prompt tokens: 437, Completion tokens: 11]\n",
      "---------- third ----------\n",
      "Let's go with the number 6.\n",
      "[Prompt tokens: 467, Completion tokens: 9]\n",
      "---------- first ----------\n",
      "Perfect! The number is 6.\n",
      "[Prompt tokens: 494, Completion tokens: 9]\n",
      "---------- Summary ----------\n",
      "Number of messages: 14\n",
      "Finish reason: Timeout of 5 seconds reached\n",
      "Total prompt tokens: 5137\n",
      "Total completion tokens: 124\n",
      "Duration: 5.13 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=323, completion_tokens=10), content='Sure! How about the number 4?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=310, completion_tokens=9), content=\"Let's go with the number 9.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=338, completion_tokens=8), content='How about the number 2?', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=364, completion_tokens=9), content='Alright, the number is 2!', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=350, completion_tokens=11), content=\"Alright, I'll go with the number 8.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=380, completion_tokens=8), content='How about the number 7?', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=406, completion_tokens=11), content=\"Sure, let's go with the number 7!\", type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=394, completion_tokens=11), content=\"Sure, let's go with the number 7!\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=424, completion_tokens=8), content='How about the number 3?', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=450, completion_tokens=10), content='Great choice! The number is 3.', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=437, completion_tokens=11), content=\"Alright, let's go with the number 3.\", type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=467, completion_tokens=9), content=\"Let's go with the number 6.\", type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=494, completion_tokens=9), content='Perfect! The number is 6.', type='TextMessage')], stop_reason='Timeout of 5 seconds reached')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TimeoutTermination\n",
    "termination = TimeoutTermination(5) # terminate when time out is met.\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "await Console(team.run_stream(task=\"Give a number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give a number\n",
      "---------- first ----------\n",
      "Sure! How about the number 5?\n",
      "[Prompt tokens: 515, Completion tokens: 10]\n",
      "---------- second ----------\n",
      "How about the number 8?\n",
      "[Prompt tokens: 475, Completion tokens: 8]\n",
      "---------- third ----------\n",
      "I'll go with the number 1.\n",
      "[Prompt tokens: 516, Completion tokens: 9]\n",
      "---------- Summary ----------\n",
      "Number of messages: 4\n",
      "Finish reason: 'third' answered\n",
      "Total prompt tokens: 1506\n",
      "Total completion tokens: 27\n",
      "Duration: 1.21 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give a number', type='TextMessage'), TextMessage(source='first', models_usage=RequestUsage(prompt_tokens=515, completion_tokens=10), content='Sure! How about the number 5?', type='TextMessage'), TextMessage(source='second', models_usage=RequestUsage(prompt_tokens=475, completion_tokens=8), content='How about the number 8?', type='TextMessage'), TextMessage(source='third', models_usage=RequestUsage(prompt_tokens=516, completion_tokens=9), content=\"I'll go with the number 1.\", type='TextMessage')], stop_reason=\"'third' answered\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SourceMatchTermination\n",
    "termination = SourceMatchTermination(\"third\") # terminate when source match agent is met.\n",
    "team = RoundRobinGroupChat([first_agent, second_agent, third_agent], termination_condition=termination)\n",
    "await Console(team.run_stream(task=\"Give a number\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
